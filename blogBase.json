{"singlePage": [], "startSite": "", "filingNum": "", "onePageListNum": 15, "commentLabelColor": "#006b75", "yearColorList": ["#bc4c00", "#0969da", "#1f883d", "#A333D0"], "i18n": "CN", "themeMode": "manual", "dayTheme": "light", "nightTheme": "dark", "urlMode": "pinyin", "script": "", "style": "", "bottomText": "", "showPostSource": 1, "iconList": {}, "UTC": 8, "rssSplit": "sentence", "exlink": {}, "useMediumZoom": 1, "title": "Simpler, Better", "subTitle": "Just for fun.", "avatarUrl": "https://github.githubassets.com/favicons/favicon.svg", "GMEEK_VERSION": "last", "postListJson": {"P1": {"htmlDir": "docs/post/Build OpenCV and OpenVINO for Windows 10 with VS 2022.html", "labels": ["opencv"], "postTitle": "Build OpenCV and OpenVINO for Windows 10 with VS 2022", "postUrl": "post/Build%20OpenCV%20and%20OpenVINO%20for%20Windows%2010%20with%20VS%202022.html", "postSourceUrl": "https://github.com/lartpang/blog/issues/1", "commentNum": 0, "wordCount": 5369, "description": "In this guide, I will build the two powerful open-source libraries, i.e., OpenCV and OpenVINO for running my deeplearning model on windows 10.\r\nInterestingly, both libraries are closely associated with Intel \ud83d\udda5\ufe0f. \r\n\r\n## OpenCV \ud83d\ude2e \r\n\r\nFirst of all, we must download the related code projects (`opencv` and `opencv_contrib` containing some plugins for `opencv`) into our computer from this links:\r\n\r\n- https://github.com/opencv/opencv/releases\r\n- https://github.com/opencv/opencv_contrib/tags\r\n\r\nMake sure the selected versions of the two libararies are the same.\r\nHere, I choice the latest version `4.7.0`.\r\nBecause we will recompiling them by ourselves, we can just download the source code zip files.\r\nPut the two unpacked libraries into the same parent folder `opencv_dir` as follows:\r\n\r\n```\r\n-opencv_dir\r\n  -opencv-4.7.0\r\n    -...\r\n  -opencv_contrib-4.7.0\r\n    -modules\r\n    -...\r\n```\r\n\r\n**NOTE**: To avoid the network issue that may be encountered during using CMake, we need to add the url proxy prefix `https://ghproxy.com/` before the urls of some setting of the relevant modules like `https://ghproxy.com/https://raw.github***`:\r\n- `.cmake` in `opencv-4.7.0/3rdparty/ippicv`\r\n- `.cmake` in `opencv-4.7.0/3rdparty/ffmpeg`\r\n- `CMakeLists.txt` in `opencv_contrib-4.7.0/modules/face`\r\n- Files in `cmake` of `opencv_contrib-4.7.0/modules/xfeatures2d`\r\n- `CMakeLists.txt` in `opencv_contrib-4.7.0/modules/wechat_qrcode`\r\n- `CMakeLists.txt` in `opencv_contrib-4.7.0/modules/cudaoptflow`\r\n\r\nNext, start compiling OpenCV.\r\n\r\n1. Create the build folder: `cd opencv_dir && mkdir opencv-build-vs2022`\r\n2. Configure and generate the VS solution by CMake with some config items:\r\n  - General:\r\n    - source folder: `<opencv-4.7.0>`\r\n    - build folder: `<opencv-build-vs2022>`\r\n    - `BUILD_OPENCV_WORLD=ON`\r\n    - `CMAKE_BUILD_TYPE=RELEASE`\r\n    - `OPENCV_ENABLE_NONFREE=ON`\r\n    - `BUILD_opencv_dnn=ON`\r\n    - `OPENCV_EXTRA_MODULES_PATH=<opencv_contrib-4.7.0/modules>`\r\n  - CUDA:\r\n    - `WITH_CUDA=ON`\r\n    - `WITH_CUDNN=ON`\r\n    - `WITH_CUBLAS=ON`\r\n    - `WITH_CUFFT=ON`\r\n    - `CUDA_FAST_MATH=ON`\r\n    - `CUDA_ARCH_BIN=7.5` (We can fill the single value corresponding to the real GPU for accelerating the compilation process.)\r\n    - `OPENCV_DNN_CUDA=ON`\r\n3. Go to the build directory: `cd <opencv-build-vs2022>`\r\n4. Start build by cmake and msvc compiler: `cmake --build . --config Release --verbose -j8`\r\n5. Install the built opencv into the `install` folder in the current path: `cmake --install . --prefix install`\r\n6. Add the `bin` directory into the user environment: `<path>\\install\\x64\\vc17\\bin`\r\n7. In VS:\r\n    - add the `<path>\\install\\include` directory into \"\u89e3\u51b3\u65b9\u6848\u8d44\u6e90\u7ba1\u7406\u5668->\u53f3\u952e\u70b9\u51fb\u5c5e\u6027->VC++\u76ee\u5f55->\u5916\u90e8\u5305\u542b\u76ee\u5f55\"\r\n    - add the `<path>\\install\\x64\\vc17\\lib` directory into \"\u89e3\u51b3\u65b9\u6848\u8d44\u6e90\u7ba1\u7406\u5668->\u53f3\u952e\u70b9\u51fb\u5c5e\u6027->VC++\u76ee\u5f55->\u5e93\u76ee\u5f55\"\r\n    - add the `opencv_world470.lib` into \"\u89e3\u51b3\u65b9\u6848\u8d44\u6e90\u7ba1\u7406\u5668->\u53f3\u952e\u70b9\u51fb\u5c5e\u6027->\u94fe\u63a5\u5668->\u8f93\u5165->\u9644\u52a0\u4f9d\u8d56\u9879\"\r\n\r\n## OpenVINO \ud83c\udf70 \r\n\r\nThe document of OpenVINO is intuitive and the readability is better than OpenCV.\r\nThe relevant content about building and installing the libirary is listed in these links:\r\n- https://github.com/openvinotoolkit/openvino/blob/master/docs/dev/build_windows.md\r\n- https://github.com/openvinotoolkit/openvino/blob/master/docs/dev/cmake_options_for_custom_comiplation.md\r\n- https://github.com/openvinotoolkit/openvino/blob/master/docs/dev/installing.md\r\n\r\nAfter building and install the OpenCV library, it's time to move on to OpenVINO.\r\n\r\n1. We need clone the project and the sub modules.\r\n    ```\r\n    git clone https://github.com/openvinotoolkit/openvino.git\r\n    cd openvino\r\n    git submodule update --init --recursive\r\n    ```\r\n2. Create the build folder: `mkdir build && cd build`\r\n3. Configure and generate the VS solution by CMake:\r\n    - `ENABLE_INTEL_GPU=OFF` (We only use the Intel CPU.)\r\n    - Disable some frontend items:\r\n      - `ENABLE_OV_PDPD_FRONTEND=OFF`\r\n      - `ENABLE_OV_TF_FRONTEND=OFF`\r\n      - `ENABLE_OV_TF_LITE_FRONTEND=OFF`\r\n      - `ENABLE_OV_PYTORCH_FRONTEND=OFF`\r\n    - For Python:\r\n      - `ENABLE_PYTHON=ON` It seems that `openvino-dev` needs to be installed first in the detected environment, otherwise a warning message will be thrown in the cmake-gui window.\r\n      - `PYTHON_EXECUTABLE=<python.exe>`\r\n      - `PYTHON_INCLUDE_DIR=<incude directory>`\r\n      - `PYTHON_LIBIRARY=<pythonxx.lib in libs directory>`\r\n    - For OpenCV:\r\n      - `ENABLE_OPENCV=ON`\r\n      - `OpenCV_DIR=<opencv-build-vs2022/install>`\r\n4. Build the library: `cmake --build . --config Release --verbose -j8`\r\n5. Install the library into the `install` directory: `cmake --install . --prefix install`\r\n6. Add the `bin` directory into the environment:\r\n    - `<path>\\install\\runtime\\bin\\intel64\\Release`\r\n    - `<path>\\install\\runtime\\3rdparty\\tbb\\bin`\r\n8. In VS:\r\n    - add the `<path>\\install\\runtime\\include` directory into \"\u89e3\u51b3\u65b9\u6848\u8d44\u6e90\u7ba1\u7406\u5668->\u53f3\u952e\u70b9\u51fb\u5c5e\u6027->VC++\u76ee\u5f55->\u5916\u90e8\u5305\u542b\u76ee\u5f55\"\r\n    - add the `<path>\\install\\runtime\\lib\\intel64\\Release` directory into \"\u89e3\u51b3\u65b9\u6848\u8d44\u6e90\u7ba1\u7406\u5668->\u53f3\u952e\u70b9\u51fb\u5c5e\u6027->VC++\u76ee\u5f55->\u5e93\u76ee\u5f55\"\r\n    - add the \ud83c\udf1f `openvino.lib`, \ud83c\udf1f `openvino_onnx_frontend.lib`, `openvino_c.lib` into \"\u89e3\u51b3\u65b9\u6848\u8d44\u6e90\u7ba1\u7406\u5668->\u53f3\u952e\u70b9\u51fb\u5c5e\u6027->\u94fe\u63a5\u5668->\u8f93\u5165->\u9644\u52a0\u4f9d\u8d56\u9879\"\r\n\r\n## Set DLL path in IDE\r\n\r\n- VS: \"right click on solution -> Properties -> Debugging -> Environment -> `PATH=<path>\\install\\x64\\vc17\\bin;%PATH%`\"\r\n- Qt Creator: \"Projects -> Build & Run -> Build/Run -> Environment -> Details -> Eidt %PATH% -> Add `<path>\\install\\x64\\vc17\\bin`\"\u3002", "top": 0, "createdAt": 1711359483, "style": "", "script": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-03-25", "dateLabelColor": "#bc4c00"}, "P2": {"htmlDir": "docs/post/Snippets of OpenVINO-CPP for Model Inference.html", "labels": ["opencv"], "postTitle": "Snippets of OpenVINO-CPP for Model Inference", "postUrl": "post/Snippets%20of%20OpenVINO-CPP%20for%20Model%20Inference.html", "postSourceUrl": "https://github.com/lartpang/blog/issues/2", "commentNum": 0, "wordCount": 2045, "description": "## Header File\r\n\r\n```cpp\r\n#include <openvino/openvino.hpp>\r\n```\r\n\r\n## Create Infer Request\r\n\r\n```cpp\r\nvoid preprocessing(std::shared_ptr<ov::Model> model) {\r\n  ov::preprocess::PrePostProcessor ppp(model);\r\n  ppp.input().tensor().set_layout(\"NHWC\"); // input data is NHWC from OpenCV Mat\r\n  ppp.input().model().set_layout(\"NCHW\"); // In the model, the layout is NCHW\r\n  model = ppp.build();\r\n}\r\n\r\nov::Core core;\r\n\r\nauto model = core.read_model(model_path); # can use onnx or openvino's xml file\r\npreprocessing(model);\r\n\r\nauto compiled_model = core.compile_model(model, \"CPU\");  // Or without `\"CPU\"`\r\nauto input_port = compiled_model.input();\r\nauto infer_request = compiled_model.create_infer_request();\r\n```\r\n\r\n## Input and Output\r\n\r\n- single input\r\n\r\n```cpp\r\ninfer_request.set_input_tensor(blob);\r\ninfer_request.crop_net.infer();\r\n```\r\n\r\n- single output\r\n\r\n```cpp\r\nov::Tensor single_output = this->point_net.get_output_tensor(0);\r\n```\r\n\r\n- multiple outputs\r\n\r\n```cpp\r\nov::Tensor multi_outputs0 = this->point_net.get_output_tensor(0);\r\nov::Tensor multi_outputs1 = this->point_net.get_output_tensor(1);\r\n```\r\n\r\n## OpenCV `cv::Mat` <-> OpenVINO `ov::Tensor`\r\n\r\nThe key to these steps is the alignment of the data layout.\r\n\r\n### `cv::Mat` -> `ov::Tensor`\r\n\r\n```cpp\r\n// converting the uint8 3-channels image mat to a float32 tensor\r\nimage.convertTo(image, CV_32FC3, 1.0 / 255);\r\n// NHWC layout as mentioned above. (N=1, C=3)\r\nov::Tensor blob(input_port.get_element_type(), input_port.get_shape(), (float *)image.data);\r\n```\r\n\r\n### `ov::Tensor` -> `cv::Mat`\r\n\r\n```cpp\r\n// tensor follows the NCHW layout, so tensor_shape is (N,C,H,W)\r\nov::Shape tensor_shape = tensor.get_shape();\r\n// Due to N=1 and C=1, we can directly assign all data to a new mat.\r\ncv::Mat mat(tensor_shape[2], tensor_shape[3], CV_32F, tensor.data());\r\n```\r\n\r\n## Reference\r\n\r\n- https://github.com/OpenVINO-dev-contest/YOLOv7_OpenVINO_cpp-python/blob/main/cpp/main_preprocessing.cpp\r\n- https://github.com/openvinotoolkit/openvino/blob/master/samples/cpp/hello_classification/main.cpp\u3002", "top": 0, "createdAt": 1711359665, "style": "", "script": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-03-25", "dateLabelColor": "#bc4c00"}, "P3": {"htmlDir": "docs/post/Six methods of indexing pixels of Mat in OpenCV.html", "labels": ["opencv"], "postTitle": "Six methods of indexing pixels of Mat in OpenCV", "postUrl": "post/Six%20methods%20of%20indexing%20pixels%20of%20Mat%20in%20OpenCV.html", "postSourceUrl": "https://github.com/lartpang/blog/issues/3", "commentNum": 0, "wordCount": 3162, "description": "## `.at<>()`\r\n\r\n```cpp\r\n// modify the pixel directly\r\nfor (int h = 0; h < image.rows; ++h) {\r\n    for (int w = 0; w < image.cols; ++w) {\r\n        image.at<Vec3b>(h, w)[0] = 255;\r\n        image.at<Vec3b>(h, w)[1] = 0;\r\n        image.at<Vec3b>(h, w)[2] = 0;\r\n    }\r\n}\r\n\r\n// modify the pixel by the reference\r\nfor (int h = 0; h < image.rows; ++h) {\r\n    for (int w = 0; w < image.cols; ++w) {\r\n        Vec3b& bgr = image.at<Vec3b>(h, w);\r\n        bgr.val[0] = 0;\r\n        bgr.val[1] = 255;\r\n        bgr.val[2] = 0;\r\n    }\r\n}\r\n\r\n// the image has one channel\r\nfor (int h = 0; h < image.rows; ++h) {\r\n    for (int w = 0; w < image.cols / 2; ++w) {\r\n        image.at<uchar>(h, w) = 128;\r\n    }\r\n}\r\n```\r\n\r\n## `.ptr<>()`\r\n\r\n```cpp\r\n// use uchar type\r\nfor (int h = 0; h < image.rows; ++h) {\r\n    for (int w = 0; w < image.cols / 2; ++w) {\r\n        uchar* ptr = image.ptr<uchar>(h, w);\r\n        ptr[0] = 255;\r\n        ptr[1] = 0;\r\n        ptr[2] = 0;\r\n    }\r\n}\r\n// use cv::Vec3b type\r\nfor (int h = 0; h < image.rows; ++h) {\r\n    for (int w = 0; w < image.cols / 2; ++w) {\r\n        Vec3b* ptr = image.ptr<Vec3b>(h, w);\r\n        ptr->val[0] = 0;\r\n        ptr->val[1] = 255;\r\n        ptr->val[2] = 0;\r\n    }\r\n}\r\n\r\n// use the row pointer and the image has one channel\r\nfor (int h = 0; h < image.rows; ++h) {\r\n    uchar* ptr = image.ptr(h);\r\n    for (int w = 0; w < image.cols / 2; ++w) {\r\n        ptr[w] = 128;\r\n    }\r\n}\r\n\r\n// use the pixel pointer and the image has one channel\r\nfor (int h = 0; h < image.rows; ++h) {\r\n    for (int w = 0; w < image.cols / 2; ++w) {\r\n        uchar* ptr = image.ptr<uchar>(h, w);\r\n        *ptr = 255;\r\n    }\r\n}\r\n```\r\n\r\n## `iterator`\r\n\r\n```cpp\r\n// the image has three channels\r\nMat_<Vec3b>::iterator it = image.begin<Vec3b>();\r\nMat_<Vec3b>::iterator itend = image.end<Vec3b>();\r\nfor (; it != itend; ++it) {\r\n    (*it)[0] = 255;\r\n    (*it)[1] = 0;\r\n    (*it)[2] = 0;\r\n}\r\n\r\n// the image has one channel\r\nMat_<uchar>::iterator it1 = image.begin<uchar>();\r\nMat_<uchar>::iterator itend1 = image.end<uchar>();\r\nfor (; it1 != itend1; ++it1) {\r\n    (*it1) = 128;\r\n}\r\n```\r\n\r\n## `.data` pointer\r\n\r\n```cpp\r\n// 3 channels\r\nuchar* data = image.data;\r\nfor (int h = 0; h < image.rows; ++h) {\r\n    for (int w = 0; w < image.cols / 2; ++w) {\r\n        *data++ = 128;\r\n        *data++ = 128;\r\n        *data++ = 128;\r\n    }\r\n}\r\n\r\n// 1 channel\r\nuchar* data = image.data;\r\nfor (int h = 0; h < image.rows; ++h) {\r\n    for (int w = 0; w < image.cols / 2; ++w) {\r\n        *data++ = 128;\r\n    }\r\n}\r\n```\r\n\r\n## `.row()` and `.col()`\r\n\r\n```cpp\r\nfor (int i = 0; i < 100; ++i) {\r\n    image.row(i).setTo(Scalar(0, 0, 0)); // modify the i th row data\r\n    image.col(i).setTo(Scalar(0, 0, 0)); // modify the i th column data\r\n}\r\n```\r\n\r\n## when `isContinuous()` is true\r\n\r\n```cpp\r\nMat image = imread(\"...\");\r\nint nRows = image.rows;\r\nint nCols = image.cols * image.channels();\r\n\r\nif (image.isContinuous()) {\r\n    nCols = nRows * nCols;\r\n    nRows = 1;\r\n}\r\n\r\nfor (int h = 0; h < nRows; ++h) {\r\n    uchar* ptr = image.ptr<uchar>(h);\r\n    for (int w = 0; w < nCols; ++w) {\r\n        // ptr[w] = 128 ;\r\n        *ptr++ = 128;\r\n    }\r\n}\r\n```\r\n\r\n## Reference\r\n\r\n- http://t.csdn.cn/bSDNn\r\n\u3002", "top": 0, "createdAt": 1711359712, "style": "", "script": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-03-25", "dateLabelColor": "#bc4c00"}, "P4": {"htmlDir": "docs/post/Tips for Qt.html", "labels": ["qt"], "postTitle": "Tips for Qt", "postUrl": "post/Tips%20for%20Qt.html", "postSourceUrl": "https://github.com/lartpang/blog/issues/4", "commentNum": 0, "wordCount": 190, "description": "## Set a proper mirror for MaintenanceTool.exe\r\n\r\nFrom: https://mirrors.tuna.tsinghua.edu.cn/help/qt/\r\n\r\n```shell\r\n.\\MaintenanceTool.exe --mirror https://mirrors.tuna.tsinghua.edu.cn/qt\r\n```\u3002", "top": 0, "createdAt": 1711360178, "style": "", "script": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-03-25", "dateLabelColor": "#bc4c00"}, "P5": {"htmlDir": "docs/post/Arixv 2403 - Parameter-Efficient Fine-Tuning for Large Models A Comprehensive Survey.html", "labels": ["paper"], "postTitle": "Arixv 2403 - Parameter-Efficient Fine-Tuning for Large Models A Comprehensive Survey", "postUrl": "post/Arixv%202403%20-%20Parameter-Efficient%20Fine-Tuning%20for%20Large%20Models%20A%20Comprehensive%20Survey.html", "postSourceUrl": "https://github.com/lartpang/blog/issues/5", "commentNum": 0, "wordCount": 32832, "description": "# Arixv 2403 | Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey\r\n\r\n![image.png](https://cdn.nlark.com/yuque/0/2024/png/192314/1711865052255-f9c75ccf-1daf-488d-ae59-fd854eef2301.png#averageHue=%23f0efef&clientId=u6331460c-e958-4&from=paste&height=176&id=u1a3b8c64&originHeight=351&originWidth=1345&originalType=binary&ratio=2&rotation=0&showTitle=false&size=104896&status=done&style=none&taskId=ue922bda5-62cc-4bb2-b22e-d0a375624b0&title=&width=672.5)\r\n\r\n* \u8bba\u6587\uff1a[https://arxiv.org/abs/2403.14608](https://arxiv.org/abs/2403.14608)\r\n* \u8bed\u96c0\u6587\u6863\uff1a[https://www.yuque.com/lart/papers/gvqrizgggd22g88n](https://www.yuque.com/lart/papers/gvqrizgggd22g88n)\r\n\r\n\u5927\u578b\u6a21\u578b\u4ee3\u8868\u4e86\u591a\u4e2a\u5e94\u7528\u9886\u57df\u7684\u7a81\u7834\u6027\u8fdb\u6b65\uff0c\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u7740\u7684\u6210\u5c31\u3002", "top": 0, "createdAt": 1712119585, "style": "", "script": "<script>MathJax = {tex: {inlineMath: [[\"$\", \"$\"]]}};</script><script async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-04-03", "dateLabelColor": "#bc4c00"}, "P6": {"htmlDir": "docs/post/ICLR 2024 - FeatUp - A Model-Agnostic Framework for Features at Any Resolution.html", "labels": ["paper"], "postTitle": "ICLR 2024 - FeatUp - A Model-Agnostic Framework for Features at Any Resolution", "postUrl": "post/ICLR%202024%20-%20FeatUp%20-%20A%20Model-Agnostic%20Framework%20for%20Features%20at%20Any%20Resolution.html", "postSourceUrl": "https://github.com/lartpang/blog/issues/6", "commentNum": 0, "wordCount": 16261, "description": "# ICLR 2024 | FeatUp: A Model-Agnostic Framework for Features at Any Resolution\r\n\r\n![image.png](https://cdn.nlark.com/yuque/0/2024/png/192314/1711687661665-4150b85f-8f4c-4849-aecf-9031439eb241.png#averageHue=%23f7f5f3&clientId=u9ddad46e-4ebe-4&from=paste&height=176&id=u5a79a7c9&originHeight=220&originWidth=727&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=32319&status=done&style=none&taskId=u5ffc5add-597a-4447-8790-5275da0e6fe&title=&width=581.6)\r\n\r\n* \u8bba\u6587\uff1a[https://arxiv.org/abs/2403.10516](https://arxiv.org/abs/2403.10516)\r\n* \u4ee3\u7801\uff1a[https://github.com/mhamilton723/FeatUp](https://github.com/mhamilton723/FeatUp)\r\n\r\n![image.png](https://cdn.nlark.com/yuque/0/2024/png/192314/1711687763372-51de525a-0b9f-402c-b70d-431f85752bc6.png#averageHue=%239ec668&clientId=u9ddad46e-4ebe-4&from=paste&height=297&id=uc56f3b36&originHeight=371&originWidth=1042&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=409622&status=done&style=none&taskId=u6b457815-6715-45e7-80e0-73492fdcc6b&title=&width=833.6)\r\n\r\n## \u80cc\u666f\u52a8\u673a\r\n\r\n\u6df1\u5c42\u7279\u5f81\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u7814\u7a76\u7684\u57fa\u77f3\uff0c\u6355\u83b7\u56fe\u50cf\u8bed\u4e49\u5e76\u4f7f\u793e\u533a\u5373\u4f7f\u5728\u96f6\u6216\u5c11\u6837\u672c\u60c5\u51b5\u4e0b\u4e5f\u80fd\u89e3\u51b3\u4e0b\u6e38\u4efb\u52a1\u3002", "top": 0, "createdAt": 1712120562, "style": "", "script": "<script>MathJax = {tex: {inlineMath: [[\"$\", \"$\"]]}};</script><script async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-04-03", "dateLabelColor": "#bc4c00"}, "P7": {"htmlDir": "docs/post/CVPR 2024 - Rethinking the Up-Sampling Operations in CNN-based Generative Network for Generalizable Deepfake Detection.html", "labels": ["paper"], "postTitle": "CVPR 2024 - Rethinking the Up-Sampling Operations in CNN-based Generative Network for Generalizable Deepfake Detection", "postUrl": "post/CVPR%202024%20-%20Rethinking%20the%20Up-Sampling%20Operations%20in%20CNN-based%20Generative%20Network%20for%20Generalizable%20Deepfake%20Detection.html", "postSourceUrl": "https://github.com/lartpang/blog/issues/7", "commentNum": 0, "wordCount": 1548, "description": "# CVPR 2024 - Rethinking the Up-Sampling Operations in CNN-based Generative Network for Generalizable Deepfake Detection\r\n\r\n* \u8bba\u6587\uff1a<https://arxiv.org/abs/2312.10461>\r\n* \u4ee3\u7801\uff1a<https://github.com/chuangchuangtan/NPR-DeepfakeDetection>\r\n\r\n![image](https://github.com/lartpang/blog/assets/26847524/0c7f34a2-8f24-458e-84c9-37b8253deb5c)\r\n\r\n\u672c\u6587\u4e3b\u8981\u7814\u7a76\u4e86\u57fa\u4e8e CNN \u7684\u751f\u6210\u7f51\u7edc\u4e2d\u7684\u4e0a\u91c7\u6837\u64cd\u4f5c\uff0c\u4ee5\u5b9e\u73b0\u901a\u7528\u7684\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u3002", "top": 0, "createdAt": 1712730171, "style": "", "script": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-04-10", "dateLabelColor": "#bc4c00"}, "P8": {"htmlDir": "docs/post/CVPR 2024 - Rethinking the Evaluation Protocol of Domain Generalization.html", "labels": ["paper"], "postTitle": "CVPR 2024 - Rethinking the Evaluation Protocol of Domain Generalization", "postUrl": "post/CVPR%202024%20-%20Rethinking%20the%20Evaluation%20Protocol%20of%20Domain%20Generalization.html", "postSourceUrl": "https://github.com/lartpang/blog/issues/8", "commentNum": 0, "wordCount": 392, "description": "# CVPR 2024 - Rethinking the Evaluation Protocol of Domain Generalization\r\n\r\n* \u8bba\u6587\uff1a<https://arxiv.org/abs/2305.15253>\r\n\r\n\u8fd9\u7bc7\u6587\u7ae0\u4e3b\u8981\u8ba8\u8bba\u4e86\u9886\u57df\u6cdb\u5316\u8bc4\u4f30\u534f\u8bae\u7684\u91cd\u65b0\u601d\u8003\uff0c\u7279\u522b\u662f\u5982\u4f55\u5904\u7406\u53ef\u80fd\u5b58\u5728\u7684\u6d4b\u8bd5\u6570\u636e\u4fe1\u606f\u6cc4\u9732\u98ce\u9669\u3002", "top": 0, "createdAt": 1712730232, "style": "", "script": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-04-10", "dateLabelColor": "#bc4c00"}, "P9": {"htmlDir": "docs/post/CVPR 2024 - Efficient Deformable ConvNets- Rethinking Dynamic and Sparse Operator for Vision Applications.html", "labels": ["paper"], "postTitle": "CVPR 2024 - Efficient Deformable ConvNets: Rethinking Dynamic and Sparse Operator for Vision Applications", "postUrl": "post/CVPR%202024%20-%20Efficient%20Deformable%20ConvNets-%20Rethinking%20Dynamic%20and%20Sparse%20Operator%20for%20Vision%20Applications.html", "postSourceUrl": "https://github.com/lartpang/blog/issues/9", "commentNum": 0, "wordCount": 667, "description": "# CVPR 2024 - Efficient Deformable ConvNets - Rethinking Dynamic and Sparse Operator for Vision Applications\r\n\r\n* \u8bba\u6587\uff1a<https://arxiv.org/abs/2401.06197>\r\n* \u4ee3\u7801\uff1a<https://github.com/OpenGVLab/DCNv4>\r\n\r\n\u672c\u6587\u63d0\u51fa\u4e86\u9ad8\u6548\u7684 DCNv4\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e13\u4e3a\u89c6\u89c9\u5e94\u7528\u8bbe\u8ba1\u7684\u9ad8\u6548\u6709\u6548\u7684\u8fd0\u7b97\u7b26\u3002", "top": 0, "createdAt": 1712730296, "style": "", "script": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-04-10", "dateLabelColor": "#bc4c00"}, "P10": {"htmlDir": "docs/post/Rethinking Interactive Image Segmentation- Feature Space Annotation.html", "labels": ["paper"], "postTitle": "Rethinking Interactive Image Segmentation: Feature Space Annotation", "postUrl": "post/Rethinking%20Interactive%20Image%20Segmentation-%20Feature%20Space%20Annotation.html", "postSourceUrl": "https://github.com/lartpang/blog/issues/10", "commentNum": 0, "wordCount": 732, "description": "# Rethinking Interactive Image Segmentation Feature Space Annotation\r\n\r\n* \u8bba\u6587\uff1a<https://arxiv.org/abs/2101.04378>\r\n* \u4ee3\u7801\uff1a<https://github.com/LIDS-UNICAMP/rethinking-interactive-image-segmentation>\r\n\r\n\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4ea4\u4e92\u5f0f\u56fe\u50cf\u5206\u5272\u65b9\u6cd5\uff0c\u901a\u8fc7\u7279\u5f81\u7a7a\u95f4\u6ce8\u91ca\u6765\u540c\u65f6\u5bf9\u591a\u5f20\u56fe\u50cf\u8fdb\u884c\u5206\u5272\u6ce8\u91ca\uff0c\u8fd9\u4e0e\u73b0\u6709\u7684\u4ea4\u4e92\u5f0f\u5206\u5272\u65b9\u6cd5\u5728\u56fe\u50cf\u9886\u57df\u8fdb\u884c\u6ce8\u89e3\u7684\u65b9\u5f0f\u5f62\u6210\u4e86\u9c9c\u660e\u5bf9\u6bd4\u3002", "top": 0, "createdAt": 1712730376, "style": "", "script": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-04-10", "dateLabelColor": "#bc4c00"}, "P11": {"htmlDir": "docs/post/CVPR 2024 - Rethinking Inductive Biases for Surface Normal Estimation.html", "labels": ["paper"], "postTitle": "CVPR 2024 - Rethinking Inductive Biases for Surface Normal Estimation", "postUrl": "post/CVPR%202024%20-%20Rethinking%20Inductive%20Biases%20for%20Surface%20Normal%20Estimation.html", "postSourceUrl": "https://github.com/lartpang/blog/issues/11", "commentNum": 0, "wordCount": 934, "description": "# CVPR 2024 - Rethinking Inductive Biases for Surface Normal Estimation\r\n\r\n* \u8bba\u6587\uff1a<https://arxiv.org/abs/2403.00712>\r\n* \u4ee3\u7801\uff1a<https://github.com/baegwangbin/DSINE>\r\n\r\n\u8be5\u7814\u7a76\u91cd\u65b0\u601d\u8003\u4e86\u8868\u9762\u6cd5\u7ebf\u4f30\u8ba1\u7684\u5f52\u7eb3\u504f\u7f6e\uff0c\u63d0\u51fa\u4e86\u5229\u7528\u9010\u50cf\u7d20\u5c04\u7ebf\u65b9\u5411\u5e76\u5b66\u4e60\u76f8\u90bb\u8868\u9762\u6cd5\u7ebf\u4e4b\u95f4\u76f8\u5bf9\u65cb\u8f6c\u5173\u7cfb\u7684\u65b9\u6cd5\u3002", "top": 0, "createdAt": 1712730469, "style": "", "script": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-04-10", "dateLabelColor": "#bc4c00"}, "P12": {"htmlDir": "docs/post/CVPR 2024 - Rethinking Interactive Image Segmentationwith Low Latency, High Quality, and Diverse Prompts.html", "labels": ["paper"], "postTitle": "CVPR 2024 - Rethinking Interactive Image Segmentationwith Low Latency, High Quality, and Diverse Prompts", "postUrl": "post/CVPR%202024%20-%20Rethinking%20Interactive%20Image%20Segmentationwith%20Low%20Latency%2C%20High%20Quality%2C%20and%20Diverse%20Prompts.html", "postSourceUrl": "https://github.com/lartpang/blog/issues/12", "commentNum": 3, "wordCount": 1110, "description": "# CVPR 2024 - Rethinking Interactive Image Segmentationwith Low Latency, High Quality, and Diverse Prompts\r\n\r\n* \u8bba\u6587\uff1a<https://arxiv.org/bas/2404.00741>\r\n* \u4ee3\u7801\uff1a<https://github.com/uncbiag/SegNext>\r\n\r\n![image](https://github.com/lartpang/blog/assets/26847524/70061347-789b-4334-bc13-012d1c713723)\r\n\r\n\u8fd9\u7bc7\u6587\u7ae0\u4e3b\u8981\u7814\u7a76\u4e86\u5982\u4f55\u5728\u4fdd\u6301\u4f4e\u5ef6\u8fdf\u7684\u540c\u65f6\u63d0\u9ad8\u4ea4\u4e92\u5f0f\u56fe\u50cf\u5206\u5272\u7684\u8d28\u91cf\uff0c\u5e76\u5b9e\u73b0\u591a\u79cd\u63d0\u793a\u7684\u517c\u5bb9\u6027\u3002", "top": 0, "createdAt": 1712731900, "style": "", "script": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-04-10", "dateLabelColor": "#bc4c00"}, "P13": {"htmlDir": "docs/post/CVPR 2024 - Retrieval-Augmented Open-Vocabulary Object Detection.html", "labels": ["paper"], "postTitle": "CVPR 2024 - Retrieval-Augmented Open-Vocabulary Object Detection", "postUrl": "post/CVPR%202024%20-%20Retrieval-Augmented%20Open-Vocabulary%20Object%20Detection.html", "postSourceUrl": "https://github.com/lartpang/blog/issues/13", "commentNum": 0, "wordCount": 1271, "description": "# CVPR 2024 - Retrieval-Augmented Open-Vocabulary Object Detection\r\n\r\n* \u8bba\u6587\uff1a<https://arxiv.org/abs/2404.05687>\r\n* \u4ee3\u7801\uff1a<https://github.com/mlvlab/RALF>\r\n\r\n\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f00\u653e\u8bcd\u6c47\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5 Retrieval-Augmented Losses and visual Features (RALF)\u3002", "top": 0, "createdAt": 1712735442, "style": "", "script": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-04-10", "dateLabelColor": "#bc4c00"}, "P14": {"htmlDir": "docs/post/CVPR 2024 - Open-Vocabulary Video Anomaly Detection.html", "labels": ["paper"], "postTitle": "CVPR 2024 - Open-Vocabulary Video Anomaly Detection", "postUrl": "post/CVPR%202024%20-%20Open-Vocabulary%20Video%20Anomaly%20Detection.html", "postSourceUrl": "https://github.com/lartpang/blog/issues/14", "commentNum": 0, "wordCount": 1929, "description": "# CVPR 2024 - Open-Vocabulary Video Anomaly Detection\r\n\r\n* \u8bba\u6587\uff1a<https://arxiv.org/abs/2311.07042>\r\n\r\n![image](https://github.com/lartpang/blog/assets/26847524/39e42922-523a-4f5f-b350-23fa5164eeab)\r\n\r\n\u8fd9\u7bc7\u6587\u7ae0\u4e3b\u8981\u7814\u7a76\u4e86\u5f00\u653e\u8bcd\u6c47\u89c6\u9891\u5f02\u5e38\u68c0\u6d4b\uff08openvocabulary video anomaly detection\uff0cOVVAD\uff09\u7684\u95ee\u9898\uff0c\u8fd9\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u4f46\u5b9e\u9645\u91cd\u8981\u7684\u95ee\u9898\u3002", "top": 0, "createdAt": 1712741986, "style": "", "script": "<script>MathJax = {tex: {inlineMath: [[\"$\", \"$\"]]}};</script><script async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-04-10", "dateLabelColor": "#bc4c00"}, "P15": {"htmlDir": "docs/post/CVPR 2024 - OVFoodSeg - Elevating Open-Vocabulary Food Image Segmentation via Image-Informed Textual Representation.html", "labels": ["paper"], "postTitle": "CVPR 2024 - OVFoodSeg - Elevating Open-Vocabulary Food Image Segmentation via Image-Informed Textual Representation", "postUrl": "post/CVPR%202024%20-%20OVFoodSeg%20-%20Elevating%20Open-Vocabulary%20Food%20Image%20Segmentation%20via%20Image-Informed%20Textual%20Representation.html", "postSourceUrl": "https://github.com/lartpang/blog/issues/15", "commentNum": 0, "wordCount": 2590, "description": "# CVPR 2024 - OVFoodSeg - Elevating Open-Vocabulary Food Image Segmentation via Image-Informed Textual Representation\r\n\r\n## \u4e3b\u8981\u5185\u5bb9\r\n\r\n\u5927\u91cf\u98df\u6750\u4e4b\u95f4\u7684\u7c7b\u522b\u5dee\u5f02\u3001\u65b0\u98df\u6750\u7684\u51fa\u73b0\u4ee5\u53ca\u4e0e\u5927\u578b\u98df\u7269\u5206\u5272\u6570\u636e\u96c6\u76f8\u5173\u7684\u9ad8\u6ce8\u91ca\u6210\u672c\u3002", "top": 0, "createdAt": 1712747543, "style": "", "script": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-04-10", "dateLabelColor": "#bc4c00"}}, "singeListJson": {}, "labelColorDict": {"bug": "#d73a4a", "documentation": "#0075ca", "duplicate": "#cfd3d7", "enhancement": "#a2eeef", "good first issue": "#7057ff", "help wanted": "#008672", "invalid": "#e4e669", "opencv": "#3108A9", "paper": "#78A3A1", "qt": "#5B7F97", "question": "#d876e3", "wontfix": "#ffffff"}, "displayTitle": "Simpler, Better", "faviconUrl": "https://github.githubassets.com/favicons/favicon.svg", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "homeUrl": "https://lartpang.github.io/blog", "prevUrl": "disabled", "nextUrl": "disabled"}