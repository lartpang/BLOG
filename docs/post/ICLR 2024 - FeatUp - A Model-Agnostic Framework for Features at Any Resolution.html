<!DOCTYPE html>
<html data-color-mode="light" data-dark-theme="dark" data-light-theme="light" lang="zh-CN">
<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href="//cdn.staticfile.net/Primer/21.0.7/primer.css" rel="stylesheet" />
    <link rel="icon" href="https://github.githubassets.com/favicons/favicon.svg"><script>
        let theme = localStorage.getItem("meek_theme") || "light";
        document.documentElement.setAttribute("data-color-mode", theme);
    </script>
<meta name="description" content="ICLR 2024 - FeatUp - A Model-Agnostic Framework for Features at Any Resolution">
<title>ICLR 2024 - FeatUp - A Model-Agnostic Framework for Features at Any Resolution</title>


</head>
<style>
body{box-sizing: border-box;min-width: 200px;max-width: 900px;margin: 20px auto;padding: 45px;font-size: 16px;font-family: sans-serif;line-height: 1.25;}
#header{display:flex;padding-bottom:8px;border-bottom: 1px solid var(--borderColor-muted, var(--color-border-muted));margin-bottom: 16px;}
#footer {margin-top:64px; text-align: center;font-size: small;}

</style>

<style>
.postTitle{margin: auto 0;font-size:40px;font-weight:bold;}
.title-right{display:flex;margin:auto 0 0 auto;}
.title-right .circle{padding: 14px 16px;margin-right:8px;}
#postBody{border-bottom: 1px solid var(--color-border-default);padding-bottom:36px;}
#postBody hr{height:2px;}
#cmButton{height:48px;margin-top:48px;}
#comments{margin-top:64px;}
.g-emoji{font-size:24px;}
@media (max-width: 600px) {
    body {padding: 8px;}
    .postTitle{font-size:24px;}
}
</style>




<body>
    <div id="header">
<h1 class="postTitle">ICLR 2024 - FeatUp - A Model-Agnostic Framework for Features at Any Resolution</h1>
<div class="title-right">
    <a href="https://lartpang.github.io/blog" id="buttonHome" class="btn btn-invisible circle" title="首页">
        <svg class="octicon" width="16" height="16">
            <path id="pathHome" fill-rule="evenodd"></path>
        </svg>
    </a>
    
    <a href="https://github.com/lartpang/blog/issues/6" target="_blank" class="btn btn-invisible circle" title="Issue">
        <svg class="octicon" width="16" height="16">
            <path id="pathIssue" fill-rule="evenodd"></path>
        </svg>
    </a>
    

    <a class="btn btn-invisible circle" onclick="modeSwitch();" title="切换主题">
        <svg class="octicon" width="16" height="16" >
            <path id="themeSwitch" fill-rule="evenodd"></path>
        </svg>
    </a>

</div>
</div>
    <div id="content">
<div class="markdown-body" id="postBody"><h1>ICLR 2024 | FeatUp: A Model-Agnostic Framework for Features at Any Resolution</h1>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/f0286b07f0723306517ef10ad013c0049ae64302dbd1fa3b3e0dd973e7209c9f/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313638373636313636352d34313530623835662d386634632d343834392d616563662d3930333134333965623234312e706e6723617665726167654875653d25323366376635663326636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3137362669643d753561373961376339266f726967696e4865696768743d323230266f726967696e57696474683d373237266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d3332333139267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7535666663356164642d353937612d343434372d383739302d3532373564613065366665267469746c653d2677696474683d3538312e36"><img src="https://camo.githubusercontent.com/f0286b07f0723306517ef10ad013c0049ae64302dbd1fa3b3e0dd973e7209c9f/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313638373636313636352d34313530623835662d386634632d343834392d616563662d3930333134333965623234312e706e6723617665726167654875653d25323366376635663326636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3137362669643d753561373961376339266f726967696e4865696768743d323230266f726967696e57696474683d373237266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d3332333139267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7535666663356164642d353937612d343434372d383739302d3532373564613065366665267469746c653d2677696474683d3538312e36" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711687661665-4150b85f-8f4c-4849-aecf-9031439eb241.png#averageHue=%23f7f5f3&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=176&amp;id=u5a79a7c9&amp;originHeight=220&amp;originWidth=727&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=32319&amp;status=done&amp;style=none&amp;taskId=u5ffc5add-597a-4447-8790-5275da0e6fe&amp;title=&amp;width=581.6" style="max-width: 100%;"></a></p>
<ul>
<li>论文：<a href="https://arxiv.org/abs/2403.10516" rel="nofollow">https://arxiv.org/abs/2403.10516</a></li>
<li>代码：<a href="https://github.com/mhamilton723/FeatUp">https://github.com/mhamilton723/FeatUp</a></li>
</ul>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/55357f50f947ff6c8248c4d94cd8a6f1250377c8415e2b2ec05075d6c348beb8/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313638373736333337322d35316465353235612d306239662d343032632d623730642d3433316638353735326263362e706e6723617665726167654875653d25323339656336363826636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3239372669643d756335366633623336266f726967696e4865696768743d333731266f726967696e57696474683d31303432266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d343039363232267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7536623435373831352d363731352d343565372d383065302d3733343932666463633662267469746c653d2677696474683d3833332e36"><img src="https://camo.githubusercontent.com/55357f50f947ff6c8248c4d94cd8a6f1250377c8415e2b2ec05075d6c348beb8/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313638373736333337322d35316465353235612d306239662d343032632d623730642d3433316638353735326263362e706e6723617665726167654875653d25323339656336363826636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3239372669643d756335366633623336266f726967696e4865696768743d333731266f726967696e57696474683d31303432266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d343039363232267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7536623435373831352d363731352d343565372d383065302d3733343932666463633662267469746c653d2677696474683d3833332e36" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711687763372-51de525a-0b9f-402c-b70d-431f85752bc6.png#averageHue=%239ec668&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=297&amp;id=uc56f3b36&amp;originHeight=371&amp;originWidth=1042&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=409622&amp;status=done&amp;style=none&amp;taskId=u6b457815-6715-45e7-80e0-73492fdcc6b&amp;title=&amp;width=833.6" style="max-width: 100%;"></a></p>
<h2>背景动机</h2>
<p>深层特征是计算机视觉研究的基石，捕获图像语义并使社区即使在零或少样本情况下也能解决下游任务。然而，这些特征通常缺乏空间分辨率来直接执行分割和深度预测等密集预测任务，因为模型会积极地池化大区域的信息。在这项工作中引入了 FeatUp，这是一个与任务和模型无关的框架，用于恢复深层特征中丢失的空间信息。</p>
<h2>相关工作</h2>
<h3>Image-adaptive Filtering</h3>
<p>自适应滤镜通常用于增强图像，同时保留其底层结构和内容。</p>
<p>例如，双边滤波器（bilateral filters）【Bilateral filtering for gray and color images，The Guided Bilateral Filter: When the Joint/Cross Bilateral Filter Becomes Robust，Fast image dehazing using guided joint bilateral filter】 将空间滤波器应用于低分辨率信号，将图像亮度滤波器应用于高分辨率引导，以混合来自二者的信息。而其重要的扩展形式，联合双边上采样（Joint Bilateral Upsampling，JBU）【Joint bilateral upsampling】，可以在高分辨率引导下对低分辨率信号进行上采样。已成功用于高效图像增强和其他应用。</p>
<p>最近一些工作嵌入了双边滤波方法【Guided Upsampling Network for Real-Time Semantic Segmentation】和非局部均值（Nonlocal Means）【A Non-Local Algorithm for Image Denoising】方法到卷积网络【Superpixel Convolutional Networks using Bilateral Inceptions，Non-local neural networks】和视觉 transformer【Blending Anti-Aliasing into Vision Transformer，Transformer for Single Image Super-Resolution】中。</p>
<ul>
<li>Shape Recipes【Shape recipes: scene representations that refer to the image】学习信号之间的局部关系以创建上采样目标信号。</li>
<li>Pixel-adaptive convolutional (PAC) 【Pixel-Adaptive Convolutional Neural Networks】使卷积运算适应输入数据，并已用于提高分割【Single-Stage Semantic Segmentation from Image Labels】和单目深度估计【Semantically-Guided Representation Learning for Self-Supervised Monocular Depth，SelfDeco: Self-Supervised Monocular Depth Completion in Challenging Indoor Environments】。</li>
<li>Spatially-Adaptive Convolution (SAC)【SqueezeSegV3: Spatially-Adaptive Convolution for Efficient Point-Cloud Segmentation】中的空间自适应卷积将自适应滤波器分解为注意力图和卷积核。</li>
<li>Bilateral Inception Module【Superpixel Convolutional Networks using Bilateral Inceptions】将双边过滤扩展到超像素，并将此操作嵌入到深层网络中以改进语义分割。</li>
</ul>
<p>这类方法在各种应用中都有效，直接将空间信息合并到任务中，同时仍然允许学习网络的灵活性。</p>
<h3>Image Super-resolution</h3>
<ul>
<li>最早的深度无监督超分辨率方法之一是零样本超分辨率 ZSSR【Zero-Shot Super-Resolution Using Deep Internal Learning】，它在测试时学习单图像网络。</li>
<li>局部隐式模型 LIIF【Learning Continuous Image Representation with Local Implicit Image Function】使用局部自适应模型来插值信息，并已被证明可以提高超分辨率网络的性能。</li>
<li>深度图像先验 DIP【Deep Image Prior】表明，CNN 可以为零样本图像去噪和超分辨率等逆问题提供归纳偏置。</li>
</ul>
<p>尽管有大量关于图像超分辨率的文献，但这些方法并不适合处理超低分辨率但高维的深层特征。</p>
<h3>General-purpose feature upsampling</h3>
<ul>
<li>双线性插值是一种广泛使用的对深度特征图进行上采样的方法。虽然有效，但这种方法模糊了信息，并且对原始图像中的内容或高分辨率结构不敏感。最近邻插值法和双三次插值法也有类似的缺点。</li>
<li>在更大的输入上评估网络可以实现更高的分辨率，但计算成本很高。此外，由于相对感受野大小的减小，这通常会降低模型性能和语义。</li>
<li>对于深度卷积网络，一种流行的技术是将最终卷积步长设置为 1【Fully Convolutional Networks for Semantic Segmentation】。然而，这种方法会产生模糊的特征，因为模型的感受野仍然很小（原文是仍然很大，似乎意思不太对）。</li>
<li>最近使用 visual transformer 的工作【Deep vit features as dense visual descriptors】对输入 patch 步幅进行了类似的修改并插入位置编码。虽然简单有效，但分辨率每增加 2 倍，这种方法就会导致计算占用量急剧增加，因此无法在实践中用于更大的上采样因子。由于前面 patch 的感受野是固定的，这种方法也会扭曲特征。</li>
</ul>
<h3>Image-adaptive feature upsampling</h3>
<ul>
<li>反卷积/转置卷积【Learning Deconvolution Network for Semantic Segmentation】使用学到的卷积核将特征转换到具有更大分辨率的新空间。</li>
<li>Resize+Convolution【Deconvolution and Checkerboard Artifacts】将学习的卷积附加到确定性上采样过程中，并减少困扰反卷积的棋盘伪影。这一设定是现在图像解码器的常见组件，并已应用于语义分割和超分辨率。</li>
<li>其他方法，如 IndexNet【Index Networks】和 Affinity-Aware Upsampling (A2U) 【Learning Affinity-Aware Upsampling for Deep Image Matting】在图像抠图方面很有效，但在其他密集预测任务上效果不佳【FADE: Fusing the Assets of Decoder and Encoder for Task-Agnostic Upsampling】。</li>
<li>Pixel-adaptive convolutional (PAC) 【Pixel-Adaptive Convolutional Neural Networks】、CARAFE【Carafe: Content-aware reassembly of features】、SAPA【Sapa: Similarity-aware point affiliation for feature upsampling】和 DGF【Fast end-to-end trainable guided filter】等方法使用可学习的输入自适应算子来转换特征。<br>
   - PAC 很灵活，但它并没有忠实地对现有特征图进行上采样，而是用于转换下游任务的特征。<br>
   - DGF 通过逐点卷积和线性映射来近似 JBU 操作，但没有完全实现 JBU，因为局部的 query/model 在计算上很难处理。这正是本文通过新的高效 CUDA 核解决的问题。<br>
   - FADE 中引入了一种新的半移位算子，并使用解码器特征来生成联合特征上采样模块。</li>
<li>Implicit Feature Alignment function (IFA)【Learning implicit feature alignment function for semantic segmentation】从不同的角度（in a different light）看待特征上采样，重点关注最近邻方法，以将编码器 - 解码器架构中的特征图与 IFA 对齐。虽然 IFA 在特定语义分割基准上表现良好，但它没有利用图像引导，也无法在编码 - 解码器框架之外学习高质量表示。</li>
</ul>
<h2>具体方法</h2>
<p>FeatUp 背后的核心直觉是，人们可以通过观察低分辨率特征的多个不同“视角”来计算高分辨率特征。</p>
<p>与 NeRF 通过在场景的许多 2D 照片之间强制一致性来构建 3D 场景的隐式表示一样，FeatUp 通过在许多低分辨率特征图之间强制一致性来构建上采样器，即认为低分辨率信号的多视图一致性可以监督高分辨率信号的构建。更具体地说，通过聚合多个“抖动”（例如翻转、填充、裁剪）图像的模型输出的低分辨率视图来学习高分辨率信息。通过学习具有多视图一致性损失的上采样网络来聚合这些信息。这一基本思想可以产生多种方法。</p>
<ol>
<li><strong>基于联合双边上采样的轻量级前向上采样器</strong>：该前馈上采样器是联合双边上采样 (JBU) 滤波器的参数化概括，通过自定义 CUDA 核函数从而比现有实现速度快了几个数量级且占用内存更少。该上采样器可以与几个卷积相当的计算成本产生与对象边缘对齐的高质量特征。</li>
<li><strong>基于隐式网络的上采样器</strong>：将隐式模型拟合到单个图像以在任何分辨率下重建特征。通过用深度隐式网络过拟合信号，针对目标图像独立学习，允许任意分辨率特征生成，同时具有较低的存储成本。</li>
</ol>
<p>在这两种上采样架构的特征可以在下游应用中直接替换使用，因为所提方法不会转换底层特征的语义，即使无需重新训练也能获得分辨率和性能提升。</p>
<p>文中的实验表明，FeatUp 在类激活图生成、分割和深度预测的迁移学习以及语义分割的端到端训练方面显着优于其他特征上采样和图像超分辨率方法。</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/7ac11f0a56ef97678ef5fad447d4a1e82b3b4f34f7c3fba12e06946d1e2bd528/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639313931333733342d34386163623961642d373639382d343264662d623164302d6632363536613239633361312e706e6723617665726167654875653d25323362616164373426636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3336342669643d753232656632623535266f726967696e4865696768743d343535266f726967696e57696474683d31303537266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d343634343939267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7562303764626238382d313531302d343363312d626161642d6165653231303035343562267469746c653d2677696474683d3834352e36"><img src="https://camo.githubusercontent.com/7ac11f0a56ef97678ef5fad447d4a1e82b3b4f34f7c3fba12e06946d1e2bd528/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639313931333733342d34386163623961642d373639382d343264662d623164302d6632363536613239633361312e706e6723617665726167654875653d25323362616164373426636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3336342669643d753232656632623535266f726967696e4865696768743d343535266f726967696e57696474683d31303537266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d343634343939267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7562303764626238382d313531302d343363312d626161642d6165653231303035343562267469746c653d2677696474683d3834352e36" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711691913734-48acb9ad-7698-42df-b1d0-f2656a29c3a1.png#averageHue=%23baad74&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=364&amp;id=u22ef2b55&amp;originHeight=455&amp;originWidth=1057&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=464499&amp;status=done&amp;style=none&amp;taskId=ub07dbb88-1510-43c1-baad-aee2100545b&amp;title=&amp;width=845.6" style="max-width: 100%;"></a></p>
<ul>
<li>第一步是生成低分辨率特征视图，以细化为单个高分辨率输出。为此用小的 padding、尺寸和水平翻转扰乱输入图像，并将模型应用于每个变换后的图像，以提取低分辨率特征图的集合。这些小的图像抖动可以帮助观察输出特征的微小差异，并提供子特征信息来训练上采样器。</li>
<li>接下来从这些视图构建一致的高分辨率特征图。假设可以学习一个潜在的高分辨率特征图。当下采样时，它可以再现低分辨率的抖动特征。FeatUp 的下采样是光线行进（ray-marching）的直接模拟；正如在此 NeRF 中将 3D 数据渲染为 2D 一样，这里的下采样器将高分辨率特征转换为低分辨率特征。与 NeRF 不同，这里不需要估计生成每个视图的参数。相反，用于 " 抖动 " 每个图像的参数被跟踪，并在下采样之前对学到的高分辨率特征应用相同的转换。然后使用高斯似然损失将下采样特征与真实模型输出进行比较【It Is Likely That Your Loss Should be a Likelihood】。<strong>一个好的高分辨率特征图应该重建所有不同视图中观察到的特征。</strong></li>
</ul>
<p>整体的多视角重建损失可以表示如下：（低分辨率特征层面上的一致性）</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/a55791383235411c04a922dd7db4112583e7f8f837668d40297c79015ebacde9/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639323536323338352d36376331303434302d613461642d343733302d383563642d6666663430376233653165612e706e6723617665726167654875653d25323366626639663826636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d36372669643d753937623266356365266f726967696e4865696768743d3834266f726967696e57696474683d363732266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d39393934267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7533613036653666362d666438322d343736322d383439302d6134613866373633396436267469746c653d2677696474683d3533372e36"><img src="https://camo.githubusercontent.com/a55791383235411c04a922dd7db4112583e7f8f837668d40297c79015ebacde9/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639323536323338352d36376331303434302d613461642d343733302d383563642d6666663430376233653165612e706e6723617665726167654875653d25323366626639663826636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d36372669643d753937623266356365266f726967696e4865696768743d3834266f726967696e57696474683d363732266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d39393934267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7533613036653666362d666438322d343736322d383439302d6134613866373633396436267469746c653d2677696474683d3533372e36" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711692562385-67c10440-a4ad-4730-85cd-fff407b3e1ea.png#averageHue=%23fbf9f8&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=67&amp;id=u97b2f5ce&amp;originHeight=84&amp;originWidth=672&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=9994&amp;status=done&amp;style=none&amp;taskId=u3a06e6f6-fd82-4762-8490-a4a8f7639d6&amp;title=&amp;width=537.6" style="max-width: 100%;"></a></p>
<ul>
<li>
$t \in T$ 代表这些小变换的集合，$x$ 为输入图像，$f$ 为模型主干。</li>
<li>
$\sigma_{\downarrow}$ 为学到的下采样器，$\sigma_{\uparrow}$ 为学到的上采样器。</li>
<li>
$F_{hr} = \sigma_{\uparrow}(f(x), x)$ 形成预测的高分辨率特征 $F_{hr}$。这种参数化允许 $\sigma_{\uparrow}$ 可以有四种形式：<br>
   - 引导上采样器（取决于 $x$ 和 $f (x)$）；<br>
   - 非引导上采样器（仅取决于 $f (x)$）；<br>
   - 隐式网络（取决于仅 $x$）；<br>
   - 特征的可学习缓存参数（不依赖任何东西，即一套可学习的参数）。</li>
<li>
$|\cdot|$ 是标准的 $l_2$ 范数。</li>
<li>
$s = \mathcal{N}(f(t(x)))$ 是空间变化的自适应不确定性【It Is Likely That Your Loss Should be a Likelihood】。这将 MSE 损失转化为能够处理不确定性的更合适的似然。这种额外的灵活性允许网络在某些异常特征从根本上无法进行上采样时进行学习。</li>
</ul>
<h3>下采样器设计</h3>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/793f54a2d31337828f25dff4358303235cc2f3301f14c61c3385499e8bf75d70/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639323030303631342d66616331613262332d313133302d343437352d613133322d6332653538623634383862322e706e6723617665726167654875653d25323364616433393326636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3236302669643d753033333865366366266f726967696e4865696768743d333235266f726967696e57696474683d31303731266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d333237333337267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7538313030616265622d393238342d346562382d626635372d3335616664633030636133267469746c653d2677696474683d3835362e38"><img src="https://camo.githubusercontent.com/793f54a2d31337828f25dff4358303235cc2f3301f14c61c3385499e8bf75d70/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639323030303631342d66616331613262332d313133302d343437352d613133322d6332653538623634383862322e706e6723617665726167654875653d25323364616433393326636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3236302669643d753033333865366366266f726967696e4865696768743d333235266f726967696e57696474683d31303731266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d333237333337267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7538313030616265622d393238342d346562382d626635372d3335616664633030636133267469746c653d2677696474683d3835362e38" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711692000614-fac1a2b3-1130-4475-a132-c2e58b6488b2.png#averageHue=%23dad393&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=260&amp;id=u0338e6cf&amp;originHeight=325&amp;originWidth=1071&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=327337&amp;status=done&amp;style=none&amp;taskId=u8100abeb-9284-4eb8-bf57-35afdc00ca3&amp;title=&amp;width=856.8" style="max-width: 100%;"></a></p>
<p>这里引入两个选项，即快速且简单的<strong>学到的模糊核</strong>，更灵活的<strong>基于注意力的下采样器</strong>。两个提出的模块都不会通过特殊变换来改变特征的 " 空间 " 或 " 语义 "，而只是在一个小邻域内插入特征。图 3 中绘制了这两种选择。</p>
<p>两个下采样器的主要超参数是核大小，对于具有较大感受野的模型（例如卷积网络），内核大小应该更大。</p>
<h4>简单的下采样器</h4>
<p>通过学到的模糊核来模糊特征，可以实现为独立应用于每个通道的卷积。学习到的核被归一化为非负且总和为 1，以确保特征保持在同一空间中。尽管这种基于模糊的下采样器非常高效，但它无法捕获动态感受野、对象显着性或其他非线性效应。</p>
<h4>更灵活的注意力下采样器</h4>
<p>可以在空间上调整下采样核。该组件使用 1x1 卷积根据高分辨率特征预测显着性图。它将显着性图与学到的空间不变权重和偏置核相结合，并对归一化结果以创建插入特征的空间变化模糊核：</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/3aabb8ea2bab0765647b3d805b23aad6e5cc3407cce5b18c5a2f686db02c9e0c/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639333535353138302d65363834376536382d303732322d343534342d626561332d3231333365373934626332362e706e6723617665726167654875653d25323366386635663226636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d33382669643d753030663365303964266f726967696e4865696768743d3437266f726967696e57696474683d363330266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d38363833267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7532376462363432652d363530352d346365622d393739652d3033323964363363656663267469746c653d2677696474683d353034"><img src="https://camo.githubusercontent.com/3aabb8ea2bab0765647b3d805b23aad6e5cc3407cce5b18c5a2f686db02c9e0c/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639333535353138302d65363834376536382d303732322d343534342d626561332d3231333365373934626332362e706e6723617665726167654875653d25323366386635663226636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d33382669643d753030663365303964266f726967696e4865696768743d3437266f726967696e57696474683d363330266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d38363833267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7532376462363432652d363530352d346365622d393739652d3033323964363363656663267469746c653d2677696474683d353034" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711693555180-e6847e68-0722-4544-bea3-2133e794bc26.png#averageHue=%23f8f5f2&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=38&amp;id=u00f3e09d&amp;originHeight=47&amp;originWidth=630&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=8683&amp;status=done&amp;style=none&amp;taskId=u27db642e-6505-4ceb-979e-0329d63cefc&amp;title=&amp;width=504" style="max-width: 100%;"></a></p>
<ul>
<li>
$\sigma_\downarrow(F)_{ij}$ 是结果特征图的第 i, j 个分量。</li>
<li>
$F_{hr}[\Omega_{ij}]$ 是指与下采样特征中的 i, j 位置相对应的高分辨率特征块。</li>
<li>
$\odot$ 和 $\cdot$ 分别指元素级乘积和向量内积。</li>
<li>
$w$ 和 $b$ 是所有补丁共享的学习权重和偏置核。</li>
</ul>
<h3>上采样器设计</h3>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/a2e373d648999f1f5c6a52f06e9e2e3b03c1514ca42e65fd46314ba050124309/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639313938343634332d34343334323832332d353236342d346338622d393065372d3132356439613939663937382e706e6723617665726167654875653d25323361646137373526636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3230302669643d753736613338363936266f726967696e4865696768743d323530266f726967696e57696474683d31303635266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d323633353830267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7536636638636439312d366162382d343664642d393362372d3663653537303361633866267469746c653d2677696474683d383532"><img src="https://camo.githubusercontent.com/a2e373d648999f1f5c6a52f06e9e2e3b03c1514ca42e65fd46314ba050124309/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639313938343634332d34343334323832332d353236342d346338622d393065372d3132356439613939663937382e706e6723617665726167654875653d25323361646137373526636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3230302669643d753736613338363936266f726967696e4865696768743d323530266f726967696e57696474683d31303635266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d323633353830267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7536636638636439312d366162382d343664642d393362372d3663653537303361633866267469746c653d2677696474683d383532" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711691984643-44342823-5264-4c8b-90e7-125d9a99f978.png#averageHue=%23ada775&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=200&amp;id=u76a38696&amp;originHeight=250&amp;originWidth=1065&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=263580&amp;status=done&amp;style=none&amp;taskId=u6cf8cd91-6ab8-46dd-93b7-6ce5703ac8f&amp;title=&amp;width=852" style="max-width: 100%;"></a></p>
<p>图中展示了本文设计的两种方法，二者都使用相同的更广泛的架构和损失进行训练。</p>
<h4>基于堆叠的联合双边上采样器的引导上采样器</h4>
<p>该架构学习了一种跨图像语料泛化的上采样策略。</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/8db34da3879154e4c813f4a33220dd3837dd6dc79e500fccd962c0fe2dcd4321/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639363739383038352d37643736313433612d326431322d346466342d393665322d3736333735346132383635382e706e6723617665726167654875653d25323366366633656626636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d32382669643d756337313939393165266f726967696e4865696768743d3335266f726967696e57696474683d343530266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d35373334267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7535363236393066622d323836372d346634302d383933632d3530623366373234646562267469746c653d2677696474683d333630"><img src="https://camo.githubusercontent.com/8db34da3879154e4c813f4a33220dd3837dd6dc79e500fccd962c0fe2dcd4321/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639363739383038352d37643736313433612d326431322d346466342d393665322d3736333735346132383635382e706e6723617665726167654875653d25323366366633656626636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d32382669643d756337313939393165266f726967696e4865696768743d3335266f726967696e57696474683d343530266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d35373334267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7535363236393066622d323836372d346634302d383933632d3530623366373234646562267469746c653d2677696474683d333630" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711696798085-7d76143a-2d12-4df4-96e2-763754a28658.png#averageHue=%23f6f3ef&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=28&amp;id=uc719991e&amp;originHeight=35&amp;originWidth=450&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=5734&amp;status=done&amp;style=none&amp;taskId=u562690fb-2867-4f40-893c-50b3f724deb&amp;title=&amp;width=360" style="max-width: 100%;"></a></p>
<p>$\circ$ 是函数组合。$f(x)$ 是低分辨率特征图。$x$ 是原始图像。</p>
<p>该架构速度快，直接将输入图像中的高频细节合并到上采样过程中，并且独立于 $f$ 的架构。</p>
<p>公式将原始 JBU 的实现推广到高维信号，并使该操作可学习。在联合双边上采样中，使用高分辨率信号 $G$ 作为低分辨率特征 $F_{lr}$ 的引导。$\Omega$ 是每个像素在引导图像中的邻域。</p>
<p>在实践中，我们使用以每个像素为中心的 3×3 正方形。令 $k(\cdot,\cdot)$ 为相似核，用于衡量两个向量的 " 接近 " 程度。然后我们可以形成联合双边过滤器：</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/0a92f6d8f526ec7d43b657ca865c9e2077b9b327cd8267406417d06af7a886a9/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639383231323430302d30646237366238612d623631392d343932392d623564312d6338653539333335323336632e706e6723617665726167654875653d25323366616639663626636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d36322669643d756536626365386630266f726967696e4865696768743d3737266f726967696e57696474683d383534266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d3136393633267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7533643363383262612d346463652d343739332d383339362d3739306338623634386334267469746c653d2677696474683d3638332e32"><img src="https://camo.githubusercontent.com/0a92f6d8f526ec7d43b657ca865c9e2077b9b327cd8267406417d06af7a886a9/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639383231323430302d30646237366238612d623631392d343932392d623564312d6338653539333335323336632e706e6723617665726167654875653d25323366616639663626636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d36322669643d756536626365386630266f726967696e4865696768743d3737266f726967696e57696474683d383534266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d3136393633267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7533643363383262612d346463652d343739332d383339362d3739306338623634386334267469746c653d2677696474683d3638332e32" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711698212400-0db76b8a-b619-4929-b5d1-c8e59335236c.png#averageHue=%23faf9f6&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=62&amp;id=ue6bce8f0&amp;originHeight=77&amp;originWidth=854&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=16963&amp;status=done&amp;style=none&amp;taskId=u3d3c82ba-4dce-4793-8396-790c8b648c4&amp;title=&amp;width=683.2" style="max-width: 100%;"></a></p>
<blockquote>
<p>原始的 JBU 形式：</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/4f1f45d5f365e0e13338e3852446f6f1d0ac5814b4b5770a3d5ee7b9629551da/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639393137303835322d61653333313630302d303135322d343836352d623261322d3936303731393031353564322e706e6723617665726167654875653d25323366336633663326636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d36382669643d756164316635356166266f726967696e4865696768743d3835266f726967696e57696474683d343339266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d36303837267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7538333733333864642d313438632d343064312d623962392d3962393132623437393437267469746c653d2677696474683d3335312e32"><img src="https://camo.githubusercontent.com/4f1f45d5f365e0e13338e3852446f6f1d0ac5814b4b5770a3d5ee7b9629551da/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639393137303835322d61653333313630302d303135322d343836352d623261322d3936303731393031353564322e706e6723617665726167654875653d25323366336633663326636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d36382669643d756164316635356166266f726967696e4865696768743d3835266f726967696e57696474683d343339266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d36303837267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7538333733333864642d313438632d343064312d623962392d3962393132623437393437267469746c653d2677696474683d3335312e32" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711699170852-ae331600-0152-4865-b2a2-9607190155d2.png#averageHue=%23f3f3f3&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=68&amp;id=uad1f55af&amp;originHeight=85&amp;originWidth=439&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=6087&amp;status=done&amp;style=none&amp;taskId=u837338dd-148c-40d1-b9b9-9b912b47947&amp;title=&amp;width=351.2" style="max-width: 100%;"></a></p>
</blockquote>
<p>其中的 $Z$ 是归一化因子，确保核参数加和为 1。spatial 核是向量坐标之间欧氏距离上宽度为 $\sigma_{spatial}$ 的可学习的高斯核：</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/4c4ae04c5580e150d22eeb3b4801b871451991587cf2c3d1adcf782f1e9172c4/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639383332303239392d33663737613464362d316264632d343730392d613735652d6339363161613538303539332e706e6723617665726167654875653d25323366396637663526636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d37322669643d753530363931616237266f726967696e4865696768743d3930266f726967696e57696474683d333936266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d38313831267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7533396162393439302d633163362d346566382d396132642d3164616261333365393335267469746c653d2677696474683d3331362e38"><img src="https://camo.githubusercontent.com/4c4ae04c5580e150d22eeb3b4801b871451991587cf2c3d1adcf782f1e9172c4/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639383332303239392d33663737613464362d316264632d343730392d613735652d6339363161613538303539332e706e6723617665726167654875653d25323366396637663526636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d37322669643d753530363931616237266f726967696e4865696768743d3930266f726967696e57696474683d333936266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d38313831267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7533396162393439302d633163362d346566382d396132642d3164616261333365393335267469746c653d2677696474683d3331362e38" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711698320299-3f77a4d6-1bdc-4709-a75e-c961aa580593.png#averageHue=%23f9f7f5&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=72&amp;id=u50691ab7&amp;originHeight=90&amp;originWidth=396&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=8181&amp;status=done&amp;style=none&amp;taskId=u39ab9490-c1c6-4ef8-9a2d-1daba33e935&amp;title=&amp;width=316.8" style="max-width: 100%;"></a></p>
<p>此外，range 核是对引导信号 $G$ 进行操作的多层感知器 (MLP) 输出内积施加温度 $\sigma_{range}^2$ 的 softmax 的形式：</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/c7fee8ef160b3ca1aa63b972546f22c7cf5ead87951790e3d7d6e843194374a9/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639383436343036372d33663762623030612d623965342d343137312d613966662d3562633761663834313637302e706e6723617665726167654875653d25323366626639663826636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d36382669643d753532303461656132266f726967696e4865696768743d3835266f726967696e57696474683d373931266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d3133373834267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7566643264313833362d313235362d343537372d393766342d3865636133313535316633267469746c653d2677696474683d3633322e38"><img src="https://camo.githubusercontent.com/c7fee8ef160b3ca1aa63b972546f22c7cf5ead87951790e3d7d6e843194374a9/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639383436343036372d33663762623030612d623965342d343137312d613966662d3562633761663834313637302e706e6723617665726167654875653d25323366626639663826636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d36382669643d753532303461656132266f726967696e4865696768743d3835266f726967696e57696474683d373931266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d3133373834267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7566643264313833362d313235362d343537372d393766342d3865636133313535316633267469746c653d2677696474683d3633322e38" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711698464067-3f7bb00a-b9e4-4171-a9ff-5bc7af841670.png#averageHue=%23fbf9f8&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=68&amp;id=u5204aea2&amp;originHeight=85&amp;originWidth=791&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=13784&amp;status=done&amp;style=none&amp;taskId=ufd2d1836-1256-4577-97f4-8eca31551f3&amp;title=&amp;width=632.8" style="max-width: 100%;"></a></p>
<p>原始 JBU 在引导信号 G 上使用固定的高斯核。而这里设计的泛化性能要好得多，因为可以从数据中学习 MLP 以创建更好的上采样器。在实验中使用具有 30 维隐藏向量和输出向量的两层 GeLU MLP。为了评估 $F_{lr}[a, b]$，如果引导像素不直接与低分辨率特征对齐，则遵循原始 JBU 公式使用双线性插值特征。为了与分辨率无关，这里在空间核中使用归一化到 [−1, 1] 的坐标距离。</p>
<p>这一形式的挑战之一是现有 JBU 实现的速度和内存性能较差。这可以解释为什么这种简单的方法没有得到更广泛的使用。为此，本文为 JBU 中使用的空间自适应内核提供了高效的 CUDA 实现。与使用 <code class="notranslate">torch.nn.Unfold</code> 运算符的简单实现相比，改进操作使用的内存减少了两个数量级，并且推理速度提高了 10 倍。</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/4a3eb4747afef275c10a225458048bad9658962dc5b4e6d00609ba72fba8a7d0/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639393538343936382d66323731623037642d326161302d343236382d613263622d3633643763373436383535342e706e6723617665726167654875653d25323366346632663026636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3338312669643d756262623961633963266f726967696e4865696768743d343736266f726967696e57696474683d363030266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d3736343035267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7561613130396665312d383338332d343566342d393138642d3638623136333337633164267469746c653d2677696474683d343830"><img src="https://camo.githubusercontent.com/4a3eb4747afef275c10a225458048bad9658962dc5b4e6d00609ba72fba8a7d0/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313639393538343936382d66323731623037642d326161302d343236382d613263622d3633643763373436383535342e706e6723617665726167654875653d25323366346632663026636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3338312669643d756262623961633963266f726967696e4865696768743d343736266f726967696e57696474683d363030266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d3736343035267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7561613130396665312d383338332d343566342d393138642d3638623136333337633164267469746c653d2677696474683d343830" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711699584968-f271b07d-2aa0-4268-a2cb-63d7c7468554.png#averageHue=%23f4f2f0&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=381&amp;id=ubbb9ac9c&amp;originHeight=476&amp;originWidth=600&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=76405&amp;status=done&amp;style=none&amp;taskId=uaa109fe1-8383-45f4-918d-68b16337c1d&amp;title=&amp;width=480" style="max-width: 100%;"></a></p>
<h4>基于隐式神经网络的图像特定的上采样器</h4>
<p>这在过度拟合单个图像时可以产生非常清晰的特征。通过使用隐式函数 $F_{hr}=MLP(z)$ 参数化单个图像的高分辨率特征。一些现有的上采样解决方案也采用这种推理时训练方法，包括 DIP 和 LIIF。这里使用小型 MLP 将图像坐标和强度映射到给定位置的高维特征。遵循先前工作【Implicit Neural Representations with Periodic Activation Functions】的指导，并使用傅里叶特征来提高隐式表示的空间分辨率。除了标准傅里叶位置特征之外，本文也表明添加傅里叶颜色特征允许网络使用原始图像中的高频颜色信息。这显着加快了收敛速度，并能够优雅地使用高分辨率图像信息，而无需使用条件随机场 (CRF) 等技术。</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/67f55ac672a5bf320066ad8acd0ad5f8dd550eaecd99f9073a6b40259e8007bb/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313730313332313438332d34613131326661612d393438322d346337302d383433372d3934653331353938363561302e706e6723617665726167654875653d25323366386636663426636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d34302669643d753337653564636139266f726967696e4865696768743d3530266f726967696e57696474683d333936266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d35353430267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7537643663626338372d363334612d343734312d396638362d3461623635646239303739267469746c653d2677696474683d3331362e38"><img src="https://camo.githubusercontent.com/67f55ac672a5bf320066ad8acd0ad5f8dd550eaecd99f9073a6b40259e8007bb/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313730313332313438332d34613131326661612d393438322d346337302d383433372d3934653331353938363561302e706e6723617665726167654875653d25323366386636663426636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d34302669643d753337653564636139266f726967696e4865696768743d3530266f726967696e57696474683d333936266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d35353430267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7537643663626338372d363334612d343734312d396638362d3461623635646239303739267469746c653d2677696474683d3331362e38" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711701321483-4a112faa-9482-4c70-8437-94e3159865a0.png#averageHue=%23f8f6f4&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=40&amp;id=u37e5dca9&amp;originHeight=50&amp;originWidth=396&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=5540&amp;status=done&amp;style=none&amp;taskId=u7d6cbc87-634a-4741-9f86-4ab65db9079&amp;title=&amp;width=316.8" style="max-width: 100%;"></a></p>
<p>$h(z,\hat{\omega})$ 表示输入信号 $z$ 的各个成分的离散傅立叶变换，其中频率向量为 $\hat{\omega}$。$e_i$ 和 $e_j$ 表示范围在区间 [−1, 1] 内的二维像素坐标场。$:$ 表示沿通道维度的拼接。</p>
<p>这里的 MLP 是一个小型 3 层 ReLU 网络，具有 dropout（$p = 0.1$）和层归一化。</p>
<p>这一设定可以使得测试时可以查询像素坐标场以产生任何分辨率下的特征。而隐式表示中的参数数量比一个 224×224 的显式表征小两个数量级以上，同时更具表现力，显着减少收敛时间和存储大小。</p>
<h3>其他细节</h3>
<h4>使用特征压缩加速训练</h4>
<ul>
<li>为了减少内存占用并进一步加速 FeatUp 隐式网络的训练，本文首先将空间变化的特征压缩到其最大的 $k=128$ 个主成分。此操作几乎是无损的，因为前 128 个分量解释了单个图像特征中 96% 的方差。这将 ResNet-50 的训练时间缩短了 60 倍，减少了内存占用，支持更大的批次，并且对学习的特征质量没有任何明显的影响。</li>
<li>在训练 JBU 上采样器时，在每个批次中对随机投影矩阵进行采样来降维，以避免在内循环中计算 PCA。得益于 Johnson–Lindenstrauss 引理 (<a href="https://spaces.ac.cn/archives/8679" rel="nofollow">让人惊叹的Johnson-Lindenstrauss引理：理论篇 - 科学空间|Scientific Spaces</a>)，这可以达到相同的效果。</li>
</ul>
<h4>总变分先验</h4>
<p>为了避免高分辨率特征中的杂散噪声，在隐式特征量值上添加一个小的 ( $\lambda_{tv}=0.05$) 总变分平滑先验：</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/c0ac2330a8a841b8a76b54ebefc1fcfab89907fba94c652020e73eb00465ccde/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313730323132313532362d64376439616438632d383230322d343262622d393562322d3337646165333732313639372e706e6723617665726167654875653d25323366626639663826636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d37362669643d756566643764306139266f726967696e4865696768743d3935266f726967696e57696474683d31303139266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d3133363233267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7530363461393635352d316331332d343164342d626530302d3434306264373736316666267469746c653d2677696474683d3831352e32"><img src="https://camo.githubusercontent.com/c0ac2330a8a841b8a76b54ebefc1fcfab89907fba94c652020e73eb00465ccde/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313730323132313532362d64376439616438632d383230322d343262622d393562322d3337646165333732313639372e706e6723617665726167654875653d25323366626639663826636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d37362669643d756566643764306139266f726967696e4865696768743d3935266f726967696e57696474683d31303139266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d3133363233267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7530363461393635352d316331332d343164342d626530302d3434306264373736316666267469746c653d2677696474683d3831352e32" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711702121526-d7d9ad8c-8202-42bb-95b2-37dae3721697.png#averageHue=%23fbf9f8&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=76&amp;id=uefd7d0a9&amp;originHeight=95&amp;originWidth=1019&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=13623&amp;status=done&amp;style=none&amp;taskId=u064a9655-1c13-41d4-be00-440bd7761ff&amp;title=&amp;width=815.2" style="max-width: 100%;"></a></p>
<p>这比正则化完整特征更快，并且避免过度规定各个组件的组织方式。注意不在 JBU 上采样器中使用它，因为此时不会受到过度拟合的影响。</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/15dbb9ee995521193b11e346bc0dd5a9b28c7df5bd13658cd22bdf0351529ad5/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313730323235393339312d63653861643337622d333363622d346439662d393263302d6563366161323064323531352e706e6723617665726167654875653d25323361396261353326636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3331322669643d756631396136393666266f726967696e4865696768743d333930266f726967696e57696474683d373339266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d343034353332267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7562326530663439652d383964662d343234642d623766652d3633653539656661636230267469746c653d2677696474683d3539312e32"><img src="https://camo.githubusercontent.com/15dbb9ee995521193b11e346bc0dd5a9b28c7df5bd13658cd22bdf0351529ad5/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313730323235393339312d63653861643337622d333363622d346439662d393263302d6563366161323064323531352e706e6723617665726167654875653d25323361396261353326636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3331322669643d756631396136393666266f726967696e4865696768743d333930266f726967696e57696474683d373339266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d343034353332267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7562326530663439652d383964662d343234642d623766652d3633653539656661636230267469746c653d2677696474683d3539312e32" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711702259391-ce8ad37b-33cb-4d9f-92c0-ec6aa20d2515.png#averageHue=%23a9ba53&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=312&amp;id=uf19a696f&amp;originHeight=390&amp;originWidth=739&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=404532&amp;status=done&amp;style=none&amp;taskId=ub2e0f49e-89df-424d-b7fe-63e59efacb0&amp;title=&amp;width=591.2" style="max-width: 100%;"></a></p>
<h2>实验结果</h2>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/77cad771fdbf6ddf517bfb5710a0f996b2e71a48b3ecc3cf28f1f70bd88705c5/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313730323338303134372d37643732333561372d333331352d343566632d626335392d3966396536343262363735352e706e6723617665726167654875653d25323366336631656526636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3336322669643d753330656337646161266f726967696e4865696768743d343532266f726967696e57696474683d31303032266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d313138353838267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7539636330643965342d373666382d343261302d386262332d3937333832333266376637267469746c653d2677696474683d3830312e36"><img src="https://camo.githubusercontent.com/77cad771fdbf6ddf517bfb5710a0f996b2e71a48b3ecc3cf28f1f70bd88705c5/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313730323338303134372d37643732333561372d333331352d343566632d626335392d3966396536343262363735352e706e6723617665726167654875653d25323366336631656526636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3336322669643d753330656337646161266f726967696e4865696768743d343532266f726967696e57696474683d31303032266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d313138353838267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7539636330643965342d373666382d343261302d386262332d3937333832333266376637267469746c653d2677696474683d3830312e36" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711702380147-7d7235a7-3315-45fc-bc59-9f9e642b6755.png#averageHue=%23f3f1ee&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=362&amp;id=u30ec7daa&amp;originHeight=452&amp;originWidth=1002&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=118588&amp;status=done&amp;style=none&amp;taskId=u9cc0d9e4-76f8-42a0-8bb3-9738232f7f7&amp;title=&amp;width=801.6" style="max-width: 100%;"></a></p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/5d38a64e9883b59ae4cd37cb805a24ad75d47c5ab23aaa913e00092c53359991/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313730323436383634352d61646131663331342d306635612d343530662d613830322d6562613437323464326561632e706e6723617665726167654875653d25323366316565656226636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3330302669643d756433323561383461266f726967696e4865696768743d333735266f726967696e57696474683d393936266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d313032343332267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7532376130363632302d343631382d343964362d393237612d3065313862373164383535267469746c653d2677696474683d3739362e38"><img src="https://camo.githubusercontent.com/5d38a64e9883b59ae4cd37cb805a24ad75d47c5ab23aaa913e00092c53359991/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313730323436383634352d61646131663331342d306635612d343530662d613830322d6562613437323464326561632e706e6723617665726167654875653d25323366316565656226636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3330302669643d756433323561383461266f726967696e4865696768743d333735266f726967696e57696474683d393936266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d313032343332267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7532376130363632302d343631382d343964362d393237612d3065313862373164383535267469746c653d2677696474683d3739362e38" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711702468645-ada1f314-0f5a-450f-a802-eba4724d2eac.png#averageHue=%23f1eeeb&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=300&amp;id=ud325a84a&amp;originHeight=375&amp;originWidth=996&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=102432&amp;status=done&amp;style=none&amp;taskId=u27a06620-4618-49d6-927a-0e18b71d855&amp;title=&amp;width=796.8" style="max-width: 100%;"></a></p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/efd245dcdde28a58dd450779279d08d2ffd017676cf98a0e72055a4b8491f40b/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313730323432303333312d33616166653035302d613262332d343662352d383438312d6639663130373637303261382e706e6723617665726167654875653d25323335626138363326636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3530322669643d753165376333333237266f726967696e4865696768743d363237266f726967696e57696474683d31303030266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d31323133323138267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7532343831663562652d353831362d343430322d626531372d6333666637346331303863267469746c653d2677696474683d383030"><img src="https://camo.githubusercontent.com/efd245dcdde28a58dd450779279d08d2ffd017676cf98a0e72055a4b8491f40b/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313730323432303333312d33616166653035302d613262332d343662352d383438312d6639663130373637303261382e706e6723617665726167654875653d25323335626138363326636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3530322669643d753165376333333237266f726967696e4865696768743d363237266f726967696e57696474683d31303030266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d31323133323138267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7532343831663562652d353831362d343430322d626531372d6333666637346331303863267469746c653d2677696474683d383030" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711702420331-3aafe050-a2b3-46b5-8481-f9f1076702a8.png#averageHue=%235ba863&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=502&amp;id=u1e7c3327&amp;originHeight=627&amp;originWidth=1000&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=1213218&amp;status=done&amp;style=none&amp;taskId=u2481f5be-5816-4402-be17-c3ff74c108c&amp;title=&amp;width=800" style="max-width: 100%;"></a></p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/07314aa908e7cefe07bd69353ad5621239831fde30e2dcdc553954911688386e/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313730323434363337382d35646238373264662d613335302d343063342d396362652d3661303535663738663636382e706e6723617665726167654875653d25323335616330346526636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3238312669643d756537353137303934266f726967696e4865696768743d333531266f726967696e57696474683d393939266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d353337343636267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7538303064303164372d316265352d346535382d393065392d3234396339636432633762267469746c653d2677696474683d3739392e32"><img src="https://camo.githubusercontent.com/07314aa908e7cefe07bd69353ad5621239831fde30e2dcdc553954911688386e/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032342f706e672f3139323331342f313731313730323434363337382d35646238373264662d613335302d343063342d396362652d3661303535663738663636382e706e6723617665726167654875653d25323335616330346526636c69656e7449643d7539646461643436652d346562652d342666726f6d3d7061737465266865696768743d3238312669643d756537353137303934266f726967696e4865696768743d333531266f726967696e57696474683d393939266f726967696e616c547970653d62696e61727926726174696f3d312e323526726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d353337343636267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7538303064303164372d316265352d346535382d393065392d3234396339636432633762267469746c653d2677696474683d3739392e32" alt="image.png" data-canonical-src="https://cdn.nlark.com/yuque/0/2024/png/192314/1711702446378-5db872df-a350-40c4-9cbe-6a055f78f668.png#averageHue=%235ac04e&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=281&amp;id=ue7517094&amp;originHeight=351&amp;originWidth=999&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=537466&amp;status=done&amp;style=none&amp;taskId=u800d01d7-1be5-4e58-90e9-249c9cd2c7b&amp;title=&amp;width=799.2" style="max-width: 100%;"></a></p></div>
<div style="font-size:small;margin-top:8px;float:right;"></div>
<button class="btn btn-block" type="button" onclick="openComments()" id="cmButton">评论</button>
<div class="comments" id="comments"></div>
</div>
    <div id="footer">Copyright © <span id="year"></span><a href="https://lartpang.github.io/blog"> Simpler, Better </a>
<p>
<span id="runday"></span>Powered by <a href="https://meekdai.com/Gmeek.html" target="_blank">Gmeek</a>
</p>

<script>
if(""!=""){
    var now=new Date();
    var startSite=new Date("");
    var diff=now.getTime()-startSite.getTime();
    var diffDay=Math.floor(diff/(1000*60*60*24));
    document.getElementById("year").innerHTML=now.getFullYear();
    if(""!=""){document.getElementById("runday").innerHTML=" • "+"网站运行"+diffDay+"天"+" • ";}
    else{document.getElementById("runday").innerHTML="网站运行"+diffDay+"天"+" • ";}
}
</script>
</div>
</body>
<script>
var IconList={'sun': 'M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z', 'moon': 'M9.598 1.591a.75.75 0 01.785-.175 7 7 0 11-8.967 8.967.75.75 0 01.961-.96 5.5 5.5 0 007.046-7.046.75.75 0 01.175-.786zm1.616 1.945a7 7 0 01-7.678 7.678 5.5 5.5 0 107.678-7.678z', 'sync': 'M1.705 8.005a.75.75 0 0 1 .834.656 5.5 5.5 0 0 0 9.592 2.97l-1.204-1.204a.25.25 0 0 1 .177-.427h3.646a.25.25 0 0 1 .25.25v3.646a.25.25 0 0 1-.427.177l-1.38-1.38A7.002 7.002 0 0 1 1.05 8.84a.75.75 0 0 1 .656-.834ZM8 2.5a5.487 5.487 0 0 0-4.131 1.869l1.204 1.204A.25.25 0 0 1 4.896 6H1.25A.25.25 0 0 1 1 5.75V2.104a.25.25 0 0 1 .427-.177l1.38 1.38A7.002 7.002 0 0 1 14.95 7.16a.75.75 0 0 1-1.49.178A5.5 5.5 0 0 0 8 2.5Z', 'home': 'M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z', 'github': 'M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z'};
var utterancesLoad=0;

let themeSettings={
    "dark": ["dark","moon","#00f0ff","dark-blue"],
    "light": ["light","sun","#ff5000","github-light"],
    "auto": ["auto","sync","","preferred-color-scheme"]
};
function changeTheme(mode, icon, color, utheme){
    document.documentElement.setAttribute("data-color-mode",mode);
    document.getElementById("themeSwitch").setAttribute("d",value=IconList[icon]);
    document.getElementById("themeSwitch").parentNode.style.color=color;
    if(utterancesLoad==1){utterancesTheme(utheme);}
}
function modeSwitch(){
    let currentMode=document.documentElement.getAttribute('data-color-mode');
    let newMode = currentMode === "light" ? "dark" : currentMode === "dark" ? "auto" : "light";
    localStorage.setItem("meek_theme", newMode);
    if(themeSettings[newMode]){
        changeTheme(...themeSettings[newMode]);
    }
}
function utterancesTheme(theme){
    const message={type:'set-theme',theme: theme};
    const iframe=document.getElementsByClassName('utterances-frame')[0];
    iframe.contentWindow.postMessage(message,'https://utteranc.es');
}
if(themeSettings[theme]){changeTheme(...themeSettings[theme]);}
console.log("\n %c Gmeek last https://github.com/Meekdai/Gmeek \n\n","padding:5px 0;background:#02d81d;color:#fff");
</script>

<script>
document.getElementById("pathHome").setAttribute("d",IconList["home"]);
document.getElementById("pathIssue").setAttribute("d",IconList["github"]);

function openComments(){
    cm=document.getElementById("comments");
    cmButton=document.getElementById("cmButton");
    cmButton.innerHTML="loading";
    span=document.createElement("span");
    span.setAttribute("class","AnimatedEllipsis");
    cmButton.appendChild(span);

    script=document.createElement("script");
    script.setAttribute("src","https://utteranc.es/client.js");
    script.setAttribute("repo","lartpang/blog");
    script.setAttribute("issue-term","title");
    
    if(localStorage.getItem("meek_theme")=="dark"){script.setAttribute("theme","dark-blue");}
    else if(localStorage.getItem("meek_theme")=="light") {script.setAttribute("theme","github-light");}
    else{script.setAttribute("theme","preferred-color-scheme");}
    
    script.setAttribute("crossorigin","anonymous");
    script.setAttribute("async","");
    cm.appendChild(script);

    int=self.setInterval("iFrameLoading()",200);
}

function iFrameLoading(){
    var utterances=document.getElementsByClassName('utterances');
    if(utterances.length==1){
        if(utterances[0].style.height!=""){
            utterancesLoad=1;
            int=window.clearInterval(int);
            document.getElementById("cmButton").style.display="none";
            console.log("utterances Load OK");
        }
    }
}
</script>


<script src='https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js'></script><script>var imgLinks = document.querySelectorAll('a > img');imgLinks.forEach(function(imgLink){var parentLink = imgLink.parentElement;parentLink.parentNode.insertBefore(parentLink.removeChild(imgLink), parentLink);parentLink.parentNode.removeChild(parentLink);});mediumZoom('img');</script><script>MathJax = {tex: {inlineMath: [["$", "$"]]}};</script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</html>
