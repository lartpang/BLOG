<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Simpler, Better</title><link>https://lartpang.github.io/blog</link><description>Just for fun.</description><copyright>Simpler, Better</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://github.githubassets.com/favicons/favicon.svg</url><title>avatar</title><link>https://lartpang.github.io/blog</link></image><lastBuildDate>Wed, 10 Apr 2024 09:46:21 +0000</lastBuildDate><managingEditor>Simpler, Better</managingEditor><ttl>60</ttl><webMaster>Simpler, Better</webMaster><item><title>CVPR 2024 - Open-Vocabulary Video Anomaly Detection</title><link>https://lartpang.github.io/blog/post/CVPR%202024%20-%20Open-Vocabulary%20Video%20Anomaly%20Detection.html</link><description># CVPR 2024 - Open-Vocabulary Video Anomaly Detection&#13;
&#13;
* è®ºæ–‡ï¼š&lt;https://arxiv.org/abs/2311.07042&gt;&#13;
&#13;
![image](https://github.com/lartpang/blog/assets/26847524/39e42922-523a-4f5f-b350-23fa5164eeab)&#13;
&#13;
è¿™ç¯‡æ–‡ç« ä¸»è¦ç ”ç©¶äº†å¼€æ”¾è¯æ±‡è§†é¢‘å¼‚å¸¸æ£€æµ‹ï¼ˆopenvocabulary video anomaly detectionï¼ŒOVVADï¼‰çš„é—®é¢˜ï¼Œè¿™æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§ä½†å®é™…é‡è¦çš„é—®é¢˜ã€‚</description><guid isPermaLink="true">https://lartpang.github.io/blog/post/CVPR%202024%20-%20Open-Vocabulary%20Video%20Anomaly%20Detection.html</guid><pubDate>Wed, 10 Apr 2024 09:39:46 +0000</pubDate></item><item><title>CVPR 2024 - Retrieval-Augmented Open-Vocabulary Object Detection</title><link>https://lartpang.github.io/blog/post/CVPR%202024%20-%20Retrieval-Augmented%20Open-Vocabulary%20Object%20Detection.html</link><description># CVPR 2024 - Retrieval-Augmented Open-Vocabulary Object Detection&#13;
&#13;
* è®ºæ–‡ï¼š&lt;https://arxiv.org/abs/2404.05687&gt;&#13;
* ä»£ç ï¼š&lt;https://github.com/mlvlab/RALF&gt;&#13;
&#13;
æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹æ–¹æ³• Retrieval-Augmented Losses and visual Features (RALF)ã€‚</description><guid isPermaLink="true">https://lartpang.github.io/blog/post/CVPR%202024%20-%20Retrieval-Augmented%20Open-Vocabulary%20Object%20Detection.html</guid><pubDate>Wed, 10 Apr 2024 07:50:42 +0000</pubDate></item><item><title>CVPR 2024 - Rethinking Interactive Image Segmentationwith Low Latency, High Quality, and Diverse Prompts</title><link>https://lartpang.github.io/blog/post/CVPR%202024%20-%20Rethinking%20Interactive%20Image%20Segmentationwith%20Low%20Latency%2C%20High%20Quality%2C%20and%20Diverse%20Prompts.html</link><description># CVPR 2024 - Rethinking Interactive Image Segmentationwith Low Latency, High Quality, and Diverse Prompts&#13;
&#13;
* è®ºæ–‡ï¼š&lt;https://arxiv.org/bas/2404.00741&gt;&#13;
* ä»£ç ï¼š&lt;https://github.com/uncbiag/SegNext&gt;&#13;
&#13;
![image](https://github.com/lartpang/blog/assets/26847524/70061347-789b-4334-bc13-012d1c713723)&#13;
&#13;
è¿™ç¯‡æ–‡ç« ä¸»è¦ç ”ç©¶äº†å¦‚ä½•åœ¨ä¿æŒä½å»¶è¿Ÿçš„åŒæ—¶æé«˜äº¤äº’å¼å›¾åƒåˆ†å‰²çš„è´¨é‡ï¼Œå¹¶å®ç°å¤šç§æç¤ºçš„å…¼å®¹æ€§ã€‚</description><guid isPermaLink="true">https://lartpang.github.io/blog/post/CVPR%202024%20-%20Rethinking%20Interactive%20Image%20Segmentationwith%20Low%20Latency%2C%20High%20Quality%2C%20and%20Diverse%20Prompts.html</guid><pubDate>Wed, 10 Apr 2024 06:51:40 +0000</pubDate></item><item><title>CVPR 2024 - Rethinking Inductive Biases for Surface Normal Estimation</title><link>https://lartpang.github.io/blog/post/CVPR%202024%20-%20Rethinking%20Inductive%20Biases%20for%20Surface%20Normal%20Estimation.html</link><description># CVPR 2024 - Rethinking Inductive Biases for Surface Normal Estimation&#13;
&#13;
* è®ºæ–‡ï¼š&lt;https://arxiv.org/abs/2403.00712&gt;&#13;
* ä»£ç ï¼š&lt;https://github.com/baegwangbin/DSINE&gt;&#13;
&#13;
è¯¥ç ”ç©¶é‡æ–°æ€è€ƒäº†è¡¨é¢æ³•çº¿ä¼°è®¡çš„å½’çº³åç½®ï¼Œæå‡ºäº†åˆ©ç”¨é€åƒç´ å°„çº¿æ–¹å‘å¹¶å­¦ä¹ ç›¸é‚»è¡¨é¢æ³•çº¿ä¹‹é—´ç›¸å¯¹æ—‹è½¬å…³ç³»çš„æ–¹æ³•ã€‚</description><guid isPermaLink="true">https://lartpang.github.io/blog/post/CVPR%202024%20-%20Rethinking%20Inductive%20Biases%20for%20Surface%20Normal%20Estimation.html</guid><pubDate>Wed, 10 Apr 2024 06:27:49 +0000</pubDate></item><item><title>Rethinking Interactive Image Segmentation: Feature Space Annotation</title><link>https://lartpang.github.io/blog/post/Rethinking%20Interactive%20Image%20Segmentation-%20Feature%20Space%20Annotation.html</link><description># Rethinking Interactive Image Segmentation Feature Space Annotation&#13;
&#13;
* è®ºæ–‡ï¼š&lt;https://arxiv.org/abs/2101.04378&gt;&#13;
* ä»£ç ï¼š&lt;https://github.com/LIDS-UNICAMP/rethinking-interactive-image-segmentation&gt;&#13;
&#13;
æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„äº¤äº’å¼å›¾åƒåˆ†å‰²æ–¹æ³•ï¼Œé€šè¿‡ç‰¹å¾ç©ºé—´æ³¨é‡Šæ¥åŒæ—¶å¯¹å¤šå¼ å›¾åƒè¿›è¡Œåˆ†å‰²æ³¨é‡Šï¼Œè¿™ä¸ç°æœ‰çš„äº¤äº’å¼åˆ†å‰²æ–¹æ³•åœ¨å›¾åƒé¢†åŸŸè¿›è¡Œæ³¨è§£çš„æ–¹å¼å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚</description><guid isPermaLink="true">https://lartpang.github.io/blog/post/Rethinking%20Interactive%20Image%20Segmentation-%20Feature%20Space%20Annotation.html</guid><pubDate>Wed, 10 Apr 2024 06:26:16 +0000</pubDate></item><item><title>CVPR 2024 - Efficient Deformable ConvNets: Rethinking Dynamic and Sparse Operator for Vision Applications</title><link>https://lartpang.github.io/blog/post/CVPR%202024%20-%20Efficient%20Deformable%20ConvNets-%20Rethinking%20Dynamic%20and%20Sparse%20Operator%20for%20Vision%20Applications.html</link><description># CVPR 2024 - Efficient Deformable ConvNets - Rethinking Dynamic and Sparse Operator for Vision Applications&#13;
&#13;
* è®ºæ–‡ï¼š&lt;https://arxiv.org/abs/2401.06197&gt;&#13;
* ä»£ç ï¼š&lt;https://github.com/OpenGVLab/DCNv4&gt;&#13;
&#13;
æœ¬æ–‡æå‡ºäº†é«˜æ•ˆçš„ DCNv4ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºè§†è§‰åº”ç”¨è®¾è®¡çš„é«˜æ•ˆæœ‰æ•ˆçš„è¿ç®—ç¬¦ã€‚</description><guid isPermaLink="true">https://lartpang.github.io/blog/post/CVPR%202024%20-%20Efficient%20Deformable%20ConvNets-%20Rethinking%20Dynamic%20and%20Sparse%20Operator%20for%20Vision%20Applications.html</guid><pubDate>Wed, 10 Apr 2024 06:24:56 +0000</pubDate></item><item><title>CVPR 2024 - Rethinking the Evaluation Protocol of Domain Generalization</title><link>https://lartpang.github.io/blog/post/CVPR%202024%20-%20Rethinking%20the%20Evaluation%20Protocol%20of%20Domain%20Generalization.html</link><description># CVPR 2024 - Rethinking the Evaluation Protocol of Domain Generalization&#13;
&#13;
* è®ºæ–‡ï¼š&lt;https://arxiv.org/abs/2305.15253&gt;&#13;
&#13;
è¿™ç¯‡æ–‡ç« ä¸»è¦è®¨è®ºäº†é¢†åŸŸæ³›åŒ–è¯„ä¼°åè®®çš„é‡æ–°æ€è€ƒï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•å¤„ç†å¯èƒ½å­˜åœ¨çš„æµ‹è¯•æ•°æ®ä¿¡æ¯æ³„éœ²é£é™©ã€‚</description><guid isPermaLink="true">https://lartpang.github.io/blog/post/CVPR%202024%20-%20Rethinking%20the%20Evaluation%20Protocol%20of%20Domain%20Generalization.html</guid><pubDate>Wed, 10 Apr 2024 06:23:52 +0000</pubDate></item><item><title>CVPR 2024 - Rethinking the Up-Sampling Operations in CNN-based Generative Network for Generalizable Deepfake Detection</title><link>https://lartpang.github.io/blog/post/CVPR%202024%20-%20Rethinking%20the%20Up-Sampling%20Operations%20in%20CNN-based%20Generative%20Network%20for%20Generalizable%20Deepfake%20Detection.html</link><description># CVPR 2024 - Rethinking the Up-Sampling Operations in CNN-based Generative Network for Generalizable Deepfake Detection&#13;
&#13;
* è®ºæ–‡ï¼š&lt;https://arxiv.org/abs/2312.10461&gt;&#13;
* ä»£ç ï¼š&lt;https://github.com/chuangchuangtan/NPR-DeepfakeDetection&gt;&#13;
&#13;
![image](https://github.com/lartpang/blog/assets/26847524/0c7f34a2-8f24-458e-84c9-37b8253deb5c)&#13;
&#13;
æœ¬æ–‡ä¸»è¦ç ”ç©¶äº†åŸºäº CNN çš„ç”Ÿæˆç½‘ç»œä¸­çš„ä¸Šé‡‡æ ·æ“ä½œï¼Œä»¥å®ç°é€šç”¨çš„æ·±åº¦ä¼ªé€ æ£€æµ‹ã€‚</description><guid isPermaLink="true">https://lartpang.github.io/blog/post/CVPR%202024%20-%20Rethinking%20the%20Up-Sampling%20Operations%20in%20CNN-based%20Generative%20Network%20for%20Generalizable%20Deepfake%20Detection.html</guid><pubDate>Wed, 10 Apr 2024 06:22:51 +0000</pubDate></item><item><title>ICLR 2024 - FeatUp - A Model-Agnostic Framework for Features at Any Resolution</title><link>https://lartpang.github.io/blog/post/ICLR%202024%20-%20FeatUp%20-%20A%20Model-Agnostic%20Framework%20for%20Features%20at%20Any%20Resolution.html</link><description># ICLR 2024 | FeatUp: A Model-Agnostic Framework for Features at Any Resolution&#13;
&#13;
![image.png](https://cdn.nlark.com/yuque/0/2024/png/192314/1711687661665-4150b85f-8f4c-4849-aecf-9031439eb241.png#averageHue=%23f7f5f3&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=176&amp;id=u5a79a7c9&amp;originHeight=220&amp;originWidth=727&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=32319&amp;status=done&amp;style=none&amp;taskId=u5ffc5add-597a-4447-8790-5275da0e6fe&amp;title=&amp;width=581.6)&#13;
&#13;
* è®ºæ–‡ï¼š[https://arxiv.org/abs/2403.10516](https://arxiv.org/abs/2403.10516)&#13;
* ä»£ç ï¼š[https://github.com/mhamilton723/FeatUp](https://github.com/mhamilton723/FeatUp)&#13;
&#13;
![image.png](https://cdn.nlark.com/yuque/0/2024/png/192314/1711687763372-51de525a-0b9f-402c-b70d-431f85752bc6.png#averageHue=%239ec668&amp;clientId=u9ddad46e-4ebe-4&amp;from=paste&amp;height=297&amp;id=uc56f3b36&amp;originHeight=371&amp;originWidth=1042&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=409622&amp;status=done&amp;style=none&amp;taskId=u6b457815-6715-45e7-80e0-73492fdcc6b&amp;title=&amp;width=833.6)&#13;
&#13;
## èƒŒæ™¯åŠ¨æœº&#13;
&#13;
æ·±å±‚ç‰¹å¾æ˜¯è®¡ç®—æœºè§†è§‰ç ”ç©¶çš„åŸºçŸ³ï¼Œæ•è·å›¾åƒè¯­ä¹‰å¹¶ä½¿ç¤¾åŒºå³ä½¿åœ¨é›¶æˆ–å°‘æ ·æœ¬æƒ…å†µä¸‹ä¹Ÿèƒ½è§£å†³ä¸‹æ¸¸ä»»åŠ¡ã€‚</description><guid isPermaLink="true">https://lartpang.github.io/blog/post/ICLR%202024%20-%20FeatUp%20-%20A%20Model-Agnostic%20Framework%20for%20Features%20at%20Any%20Resolution.html</guid><pubDate>Wed, 03 Apr 2024 05:02:42 +0000</pubDate></item><item><title>Arixv 2403 - Parameter-Efficient Fine-Tuning for Large Models A Comprehensive Survey</title><link>https://lartpang.github.io/blog/post/Arixv%202403%20-%20Parameter-Efficient%20Fine-Tuning%20for%20Large%20Models%20A%20Comprehensive%20Survey.html</link><description># Arixv 2403 | Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey&#13;
&#13;
![image.png](https://cdn.nlark.com/yuque/0/2024/png/192314/1711865052255-f9c75ccf-1daf-488d-ae59-fd854eef2301.png#averageHue=%23f0efef&amp;clientId=u6331460c-e958-4&amp;from=paste&amp;height=176&amp;id=u1a3b8c64&amp;originHeight=351&amp;originWidth=1345&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=104896&amp;status=done&amp;style=none&amp;taskId=ue922bda5-62cc-4bb2-b22e-d0a375624b0&amp;title=&amp;width=672.5)&#13;
&#13;
* è®ºæ–‡ï¼š[https://arxiv.org/abs/2403.14608](https://arxiv.org/abs/2403.14608)&#13;
* è¯­é›€æ–‡æ¡£ï¼š[https://www.yuque.com/lart/papers/gvqrizgggd22g88n](https://www.yuque.com/lart/papers/gvqrizgggd22g88n)&#13;
&#13;
å¤§å‹æ¨¡å‹ä»£è¡¨äº†å¤šä¸ªåº”ç”¨é¢†åŸŸçš„çªç ´æ€§è¿›æ­¥ï¼Œåœ¨å„ç§ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾ç€çš„æˆå°±ã€‚</description><guid isPermaLink="true">https://lartpang.github.io/blog/post/Arixv%202403%20-%20Parameter-Efficient%20Fine-Tuning%20for%20Large%20Models%20A%20Comprehensive%20Survey.html</guid><pubDate>Wed, 03 Apr 2024 04:46:25 +0000</pubDate></item><item><title>Tips for Qt</title><link>https://lartpang.github.io/blog/post/Tips%20for%20Qt.html</link><description>## Set a proper mirror for MaintenanceTool.exe&#13;
&#13;
From: https://mirrors.tuna.tsinghua.edu.cn/help/qt/&#13;
&#13;
```shell&#13;
.\MaintenanceTool.exe --mirror https://mirrors.tuna.tsinghua.edu.cn/qt&#13;
```ã€‚</description><guid isPermaLink="true">https://lartpang.github.io/blog/post/Tips%20for%20Qt.html</guid><pubDate>Mon, 25 Mar 2024 09:49:38 +0000</pubDate></item><item><title>Six methods of indexing pixels of Mat in OpenCV</title><link>https://lartpang.github.io/blog/post/Six%20methods%20of%20indexing%20pixels%20of%20Mat%20in%20OpenCV.html</link><description>## `.at&lt;&gt;()`&#13;
&#13;
```cpp&#13;
// modify the pixel directly&#13;
for (int h = 0; h &lt; image.rows; ++h) {&#13;
    for (int w = 0; w &lt; image.cols; ++w) {&#13;
        image.at&lt;Vec3b&gt;(h, w)[0] = 255;&#13;
        image.at&lt;Vec3b&gt;(h, w)[1] = 0;&#13;
        image.at&lt;Vec3b&gt;(h, w)[2] = 0;&#13;
    }&#13;
}&#13;
&#13;
// modify the pixel by the reference&#13;
for (int h = 0; h &lt; image.rows; ++h) {&#13;
    for (int w = 0; w &lt; image.cols; ++w) {&#13;
        Vec3b&amp; bgr = image.at&lt;Vec3b&gt;(h, w);&#13;
        bgr.val[0] = 0;&#13;
        bgr.val[1] = 255;&#13;
        bgr.val[2] = 0;&#13;
    }&#13;
}&#13;
&#13;
// the image has one channel&#13;
for (int h = 0; h &lt; image.rows; ++h) {&#13;
    for (int w = 0; w &lt; image.cols / 2; ++w) {&#13;
        image.at&lt;uchar&gt;(h, w) = 128;&#13;
    }&#13;
}&#13;
```&#13;
&#13;
## `.ptr&lt;&gt;()`&#13;
&#13;
```cpp&#13;
// use uchar type&#13;
for (int h = 0; h &lt; image.rows; ++h) {&#13;
    for (int w = 0; w &lt; image.cols / 2; ++w) {&#13;
        uchar* ptr = image.ptr&lt;uchar&gt;(h, w);&#13;
        ptr[0] = 255;&#13;
        ptr[1] = 0;&#13;
        ptr[2] = 0;&#13;
    }&#13;
}&#13;
// use cv::Vec3b type&#13;
for (int h = 0; h &lt; image.rows; ++h) {&#13;
    for (int w = 0; w &lt; image.cols / 2; ++w) {&#13;
        Vec3b* ptr = image.ptr&lt;Vec3b&gt;(h, w);&#13;
        ptr-&gt;val[0] = 0;&#13;
        ptr-&gt;val[1] = 255;&#13;
        ptr-&gt;val[2] = 0;&#13;
    }&#13;
}&#13;
&#13;
// use the row pointer and the image has one channel&#13;
for (int h = 0; h &lt; image.rows; ++h) {&#13;
    uchar* ptr = image.ptr(h);&#13;
    for (int w = 0; w &lt; image.cols / 2; ++w) {&#13;
        ptr[w] = 128;&#13;
    }&#13;
}&#13;
&#13;
// use the pixel pointer and the image has one channel&#13;
for (int h = 0; h &lt; image.rows; ++h) {&#13;
    for (int w = 0; w &lt; image.cols / 2; ++w) {&#13;
        uchar* ptr = image.ptr&lt;uchar&gt;(h, w);&#13;
        *ptr = 255;&#13;
    }&#13;
}&#13;
```&#13;
&#13;
## `iterator`&#13;
&#13;
```cpp&#13;
// the image has three channels&#13;
Mat_&lt;Vec3b&gt;::iterator it = image.begin&lt;Vec3b&gt;();&#13;
Mat_&lt;Vec3b&gt;::iterator itend = image.end&lt;Vec3b&gt;();&#13;
for (; it != itend; ++it) {&#13;
    (*it)[0] = 255;&#13;
    (*it)[1] = 0;&#13;
    (*it)[2] = 0;&#13;
}&#13;
&#13;
// the image has one channel&#13;
Mat_&lt;uchar&gt;::iterator it1 = image.begin&lt;uchar&gt;();&#13;
Mat_&lt;uchar&gt;::iterator itend1 = image.end&lt;uchar&gt;();&#13;
for (; it1 != itend1; ++it1) {&#13;
    (*it1) = 128;&#13;
}&#13;
```&#13;
&#13;
## `.data` pointer&#13;
&#13;
```cpp&#13;
// 3 channels&#13;
uchar* data = image.data;&#13;
for (int h = 0; h &lt; image.rows; ++h) {&#13;
    for (int w = 0; w &lt; image.cols / 2; ++w) {&#13;
        *data++ = 128;&#13;
        *data++ = 128;&#13;
        *data++ = 128;&#13;
    }&#13;
}&#13;
&#13;
// 1 channel&#13;
uchar* data = image.data;&#13;
for (int h = 0; h &lt; image.rows; ++h) {&#13;
    for (int w = 0; w &lt; image.cols / 2; ++w) {&#13;
        *data++ = 128;&#13;
    }&#13;
}&#13;
```&#13;
&#13;
## `.row()` and `.col()`&#13;
&#13;
```cpp&#13;
for (int i = 0; i &lt; 100; ++i) {&#13;
    image.row(i).setTo(Scalar(0, 0, 0)); // modify the i th row data&#13;
    image.col(i).setTo(Scalar(0, 0, 0)); // modify the i th column data&#13;
}&#13;
```&#13;
&#13;
## when `isContinuous()` is true&#13;
&#13;
```cpp&#13;
Mat image = imread("...");&#13;
int nRows = image.rows;&#13;
int nCols = image.cols * image.channels();&#13;
&#13;
if (image.isContinuous()) {&#13;
    nCols = nRows * nCols;&#13;
    nRows = 1;&#13;
}&#13;
&#13;
for (int h = 0; h &lt; nRows; ++h) {&#13;
    uchar* ptr = image.ptr&lt;uchar&gt;(h);&#13;
    for (int w = 0; w &lt; nCols; ++w) {&#13;
        // ptr[w] = 128 ;&#13;
        *ptr++ = 128;&#13;
    }&#13;
}&#13;
```&#13;
&#13;
## Reference&#13;
&#13;
- http://t.csdn.cn/bSDNn&#13;
ã€‚</description><guid isPermaLink="true">https://lartpang.github.io/blog/post/Six%20methods%20of%20indexing%20pixels%20of%20Mat%20in%20OpenCV.html</guid><pubDate>Mon, 25 Mar 2024 09:41:52 +0000</pubDate></item><item><title>Snippets of OpenVINO-CPP for Model Inference</title><link>https://lartpang.github.io/blog/post/Snippets%20of%20OpenVINO-CPP%20for%20Model%20Inference.html</link><description>## Header File&#13;
&#13;
```cpp&#13;
#include &lt;openvino/openvino.hpp&gt;&#13;
```&#13;
&#13;
## Create Infer Request&#13;
&#13;
```cpp&#13;
void preprocessing(std::shared_ptr&lt;ov::Model&gt; model) {&#13;
  ov::preprocess::PrePostProcessor ppp(model);&#13;
  ppp.input().tensor().set_layout("NHWC"); // input data is NHWC from OpenCV Mat&#13;
  ppp.input().model().set_layout("NCHW"); // In the model, the layout is NCHW&#13;
  model = ppp.build();&#13;
}&#13;
&#13;
ov::Core core;&#13;
&#13;
auto model = core.read_model(model_path); # can use onnx or openvino's xml file&#13;
preprocessing(model);&#13;
&#13;
auto compiled_model = core.compile_model(model, "CPU");  // Or without `"CPU"`&#13;
auto input_port = compiled_model.input();&#13;
auto infer_request = compiled_model.create_infer_request();&#13;
```&#13;
&#13;
## Input and Output&#13;
&#13;
- single input&#13;
&#13;
```cpp&#13;
infer_request.set_input_tensor(blob);&#13;
infer_request.crop_net.infer();&#13;
```&#13;
&#13;
- single output&#13;
&#13;
```cpp&#13;
ov::Tensor single_output = this-&gt;point_net.get_output_tensor(0);&#13;
```&#13;
&#13;
- multiple outputs&#13;
&#13;
```cpp&#13;
ov::Tensor multi_outputs0 = this-&gt;point_net.get_output_tensor(0);&#13;
ov::Tensor multi_outputs1 = this-&gt;point_net.get_output_tensor(1);&#13;
```&#13;
&#13;
## OpenCV `cv::Mat` &lt;-&gt; OpenVINO `ov::Tensor`&#13;
&#13;
The key to these steps is the alignment of the data layout.&#13;
&#13;
### `cv::Mat` -&gt; `ov::Tensor`&#13;
&#13;
```cpp&#13;
// converting the uint8 3-channels image mat to a float32 tensor&#13;
image.convertTo(image, CV_32FC3, 1.0 / 255);&#13;
// NHWC layout as mentioned above. (N=1, C=3)&#13;
ov::Tensor blob(input_port.get_element_type(), input_port.get_shape(), (float *)image.data);&#13;
```&#13;
&#13;
### `ov::Tensor` -&gt; `cv::Mat`&#13;
&#13;
```cpp&#13;
// tensor follows the NCHW layout, so tensor_shape is (N,C,H,W)&#13;
ov::Shape tensor_shape = tensor.get_shape();&#13;
// Due to N=1 and C=1, we can directly assign all data to a new mat.&#13;
cv::Mat mat(tensor_shape[2], tensor_shape[3], CV_32F, tensor.data());&#13;
```&#13;
&#13;
## Reference&#13;
&#13;
- https://github.com/OpenVINO-dev-contest/YOLOv7_OpenVINO_cpp-python/blob/main/cpp/main_preprocessing.cpp&#13;
- https://github.com/openvinotoolkit/openvino/blob/master/samples/cpp/hello_classification/main.cppã€‚</description><guid isPermaLink="true">https://lartpang.github.io/blog/post/Snippets%20of%20OpenVINO-CPP%20for%20Model%20Inference.html</guid><pubDate>Mon, 25 Mar 2024 09:41:05 +0000</pubDate></item><item><title>Build OpenCV and OpenVINO for Windows 10 with VS 2022</title><link>https://lartpang.github.io/blog/post/Build%20OpenCV%20and%20OpenVINO%20for%20Windows%2010%20with%20VS%202022.html</link><description>In this guide, I will build the two powerful open-source libraries, i.e., OpenCV and OpenVINO for running my deeplearning model on windows 10.&#13;
Interestingly, both libraries are closely associated with Intel ğŸ–¥ï¸. &#13;
&#13;
## OpenCV ğŸ˜® &#13;
&#13;
First of all, we must download the related code projects (`opencv` and `opencv_contrib` containing some plugins for `opencv`) into our computer from this links:&#13;
&#13;
- https://github.com/opencv/opencv/releases&#13;
- https://github.com/opencv/opencv_contrib/tags&#13;
&#13;
Make sure the selected versions of the two libararies are the same.&#13;
Here, I choice the latest version `4.7.0`.&#13;
Because we will recompiling them by ourselves, we can just download the source code zip files.&#13;
Put the two unpacked libraries into the same parent folder `opencv_dir` as follows:&#13;
&#13;
```&#13;
-opencv_dir&#13;
  -opencv-4.7.0&#13;
    -...&#13;
  -opencv_contrib-4.7.0&#13;
    -modules&#13;
    -...&#13;
```&#13;
&#13;
**NOTE**: To avoid the network issue that may be encountered during using CMake, we need to add the url proxy prefix `https://ghproxy.com/` before the urls of some setting of the relevant modules like `https://ghproxy.com/https://raw.github***`:&#13;
- `.cmake` in `opencv-4.7.0/3rdparty/ippicv`&#13;
- `.cmake` in `opencv-4.7.0/3rdparty/ffmpeg`&#13;
- `CMakeLists.txt` in `opencv_contrib-4.7.0/modules/face`&#13;
- Files in `cmake` of `opencv_contrib-4.7.0/modules/xfeatures2d`&#13;
- `CMakeLists.txt` in `opencv_contrib-4.7.0/modules/wechat_qrcode`&#13;
- `CMakeLists.txt` in `opencv_contrib-4.7.0/modules/cudaoptflow`&#13;
&#13;
Next, start compiling OpenCV.&#13;
&#13;
1. Create the build folder: `cd opencv_dir &amp;&amp; mkdir opencv-build-vs2022`&#13;
2. Configure and generate the VS solution by CMake with some config items:&#13;
  - General:&#13;
    - source folder: `&lt;opencv-4.7.0&gt;`&#13;
    - build folder: `&lt;opencv-build-vs2022&gt;`&#13;
    - `BUILD_OPENCV_WORLD=ON`&#13;
    - `CMAKE_BUILD_TYPE=RELEASE`&#13;
    - `OPENCV_ENABLE_NONFREE=ON`&#13;
    - `BUILD_opencv_dnn=ON`&#13;
    - `OPENCV_EXTRA_MODULES_PATH=&lt;opencv_contrib-4.7.0/modules&gt;`&#13;
  - CUDA:&#13;
    - `WITH_CUDA=ON`&#13;
    - `WITH_CUDNN=ON`&#13;
    - `WITH_CUBLAS=ON`&#13;
    - `WITH_CUFFT=ON`&#13;
    - `CUDA_FAST_MATH=ON`&#13;
    - `CUDA_ARCH_BIN=7.5` (We can fill the single value corresponding to the real GPU for accelerating the compilation process.)&#13;
    - `OPENCV_DNN_CUDA=ON`&#13;
3. Go to the build directory: `cd &lt;opencv-build-vs2022&gt;`&#13;
4. Start build by cmake and msvc compiler: `cmake --build . --config Release --verbose -j8`&#13;
5. Install the built opencv into the `install` folder in the current path: `cmake --install . --prefix install`&#13;
6. Add the `bin` directory into the user environment: `&lt;path&gt;\install\x64\vc17\bin`&#13;
7. In VS:&#13;
    - add the `&lt;path&gt;\install\include` directory into "è§£å†³æ–¹æ¡ˆèµ„æºç®¡ç†å™¨-&gt;å³é”®ç‚¹å‡»å±æ€§-&gt;VC++ç›®å½•-&gt;å¤–éƒ¨åŒ…å«ç›®å½•"&#13;
    - add the `&lt;path&gt;\install\x64\vc17\lib` directory into "è§£å†³æ–¹æ¡ˆèµ„æºç®¡ç†å™¨-&gt;å³é”®ç‚¹å‡»å±æ€§-&gt;VC++ç›®å½•-&gt;åº“ç›®å½•"&#13;
    - add the `opencv_world470.lib` into "è§£å†³æ–¹æ¡ˆèµ„æºç®¡ç†å™¨-&gt;å³é”®ç‚¹å‡»å±æ€§-&gt;é“¾æ¥å™¨-&gt;è¾“å…¥-&gt;é™„åŠ ä¾èµ–é¡¹"&#13;
&#13;
## OpenVINO ğŸ° &#13;
&#13;
The document of OpenVINO is intuitive and the readability is better than OpenCV.&#13;
The relevant content about building and installing the libirary is listed in these links:&#13;
- https://github.com/openvinotoolkit/openvino/blob/master/docs/dev/build_windows.md&#13;
- https://github.com/openvinotoolkit/openvino/blob/master/docs/dev/cmake_options_for_custom_comiplation.md&#13;
- https://github.com/openvinotoolkit/openvino/blob/master/docs/dev/installing.md&#13;
&#13;
After building and install the OpenCV library, it's time to move on to OpenVINO.&#13;
&#13;
1. We need clone the project and the sub modules.&#13;
    ```&#13;
    git clone https://github.com/openvinotoolkit/openvino.git&#13;
    cd openvino&#13;
    git submodule update --init --recursive&#13;
    ```&#13;
2. Create the build folder: `mkdir build &amp;&amp; cd build`&#13;
3. Configure and generate the VS solution by CMake:&#13;
    - `ENABLE_INTEL_GPU=OFF` (We only use the Intel CPU.)&#13;
    - Disable some frontend items:&#13;
      - `ENABLE_OV_PDPD_FRONTEND=OFF`&#13;
      - `ENABLE_OV_TF_FRONTEND=OFF`&#13;
      - `ENABLE_OV_TF_LITE_FRONTEND=OFF`&#13;
      - `ENABLE_OV_PYTORCH_FRONTEND=OFF`&#13;
    - For Python:&#13;
      - `ENABLE_PYTHON=ON` It seems that `openvino-dev` needs to be installed first in the detected environment, otherwise a warning message will be thrown in the cmake-gui window.&#13;
      - `PYTHON_EXECUTABLE=&lt;python.exe&gt;`&#13;
      - `PYTHON_INCLUDE_DIR=&lt;incude directory&gt;`&#13;
      - `PYTHON_LIBIRARY=&lt;pythonxx.lib in libs directory&gt;`&#13;
    - For OpenCV:&#13;
      - `ENABLE_OPENCV=ON`&#13;
      - `OpenCV_DIR=&lt;opencv-build-vs2022/install&gt;`&#13;
4. Build the library: `cmake --build . --config Release --verbose -j8`&#13;
5. Install the library into the `install` directory: `cmake --install . --prefix install`&#13;
6. Add the `bin` directory into the environment:&#13;
    - `&lt;path&gt;\install\runtime\bin\intel64\Release`&#13;
    - `&lt;path&gt;\install\runtime\3rdparty\tbb\bin`&#13;
8. In VS:&#13;
    - add the `&lt;path&gt;\install\runtime\include` directory into "è§£å†³æ–¹æ¡ˆèµ„æºç®¡ç†å™¨-&gt;å³é”®ç‚¹å‡»å±æ€§-&gt;VC++ç›®å½•-&gt;å¤–éƒ¨åŒ…å«ç›®å½•"&#13;
    - add the `&lt;path&gt;\install\runtime\lib\intel64\Release` directory into "è§£å†³æ–¹æ¡ˆèµ„æºç®¡ç†å™¨-&gt;å³é”®ç‚¹å‡»å±æ€§-&gt;VC++ç›®å½•-&gt;åº“ç›®å½•"&#13;
    - add the ğŸŒŸ `openvino.lib`, ğŸŒŸ `openvino_onnx_frontend.lib`, `openvino_c.lib` into "è§£å†³æ–¹æ¡ˆèµ„æºç®¡ç†å™¨-&gt;å³é”®ç‚¹å‡»å±æ€§-&gt;é“¾æ¥å™¨-&gt;è¾“å…¥-&gt;é™„åŠ ä¾èµ–é¡¹"&#13;
&#13;
## Set DLL path in IDE&#13;
&#13;
- VS: "right click on solution -&gt; Properties -&gt; Debugging -&gt; Environment -&gt; `PATH=&lt;path&gt;\install\x64\vc17\bin;%PATH%`"&#13;
- Qt Creator: "Projects -&gt; Build &amp; Run -&gt; Build/Run -&gt; Environment -&gt; Details -&gt; Eidt %PATH% -&gt; Add `&lt;path&gt;\install\x64\vc17\bin`"ã€‚</description><guid isPermaLink="true">https://lartpang.github.io/blog/post/Build%20OpenCV%20and%20OpenVINO%20for%20Windows%2010%20with%20VS%202022.html</guid><pubDate>Mon, 25 Mar 2024 09:38:03 +0000</pubDate></item></channel></rss>